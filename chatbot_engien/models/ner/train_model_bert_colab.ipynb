{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":396,"status":"ok","timestamp":1693189710041,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"5FVd64fv-Cvw"},"outputs":[],"source":["# 학습 파일 불러오기\n","def read_file(file_name):\n","    sents = []\n","    with open(file_name, 'r', encoding='utf-8') as f:\n","        lines = f.readlines()\n","        for idx, l in enumerate(lines):\n","            if l[0] == ';' and lines[idx + 1][0] == '$':\n","                this_sent = []\n","            elif l[0] == '$' and lines[idx - 1][0] == ';':\n","                continue\n","            elif l[0] == '\\n':\n","                sents.append(this_sent)\n","            else:\n","                this_sent.append(tuple(l.split()))\n","    return sents\n","\n","\n","def convert_examples_to_features(examples, labels, max_seq_len, tokenizer, pad_token_id_for_segment=0,\n","                                     pad_token_id_for_label=-100):\n","    cls_token = tokenizer.cls_token\n","    sep_token = tokenizer.sep_token\n","    pad_token_id = tokenizer.pad_token_id\n","    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n","\n","    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n","        tokens = []\n","        labels_ids = []\n","        for one_word, label_token in zip(example, label):\n","            #하나의 단어에 대해서 서브워드로 토큰화\n","            subword_tokens = tokenizer.tokenize(one_word)\n","            tokens.extend(subword_tokens)\n","            #서브워드 중 첫번째 서브워드만 개체명 레이블을 부여하고 그 외에는 -100으로 채운다.\n","            labels_ids.extend([tag_to_index[label_token]]+ [pad_token_id_for_label] * (len(subword_tokens) - 1))\n","            #[CLS]와[SEP]를 후에 추가할 것을 고려하여 최대 길이를 초과하는 샘플의 경 우 max_seq_len-2의 길이로 변환.\n","            #ex)max_seq_len=64라면 길이가62보다 긴 샘플은 뒷 부분을 자르고 길이 62로 변환.\n","        special_tokens_count = 2\n","        if len(tokens) > max_seq_len - special_tokens_count:\n","            tokens = tokens[:(max_seq_len - special_tokens_count)]\n","            labels_ids = labels_ids[:(max_seq_len - special_tokens_count)]\n","        #[SEP]를 추가하는 코드\n","        #1.토큰화 결과의 맨 뒷 부분에[SEP]토큰 추가 #2. 레이블에도 맨 뒷 부분에 -100 추가.\n","        tokens += [sep_token]\n","        labels_ids += [pad_token_id_for_label]\n","        #[CLS]를 추가하는 코드\n","        #1. 토큰화 결과의 앞 부분에 [CLS] 토큰 추가\n","        #2. 레이블의 맨 앞 부분에도 -100 추가.\n","        tokens = [cls_token] + tokens\n","        labels_ids = [pad_token_id_for_label] + labels_ids\n","        #정수 인코딩\n","        input_id = tokenizer.convert_tokens_to_ids(tokens)\n","        #어텐션 마스크 생성\n","        attention_mask = [1] * len(input_id)\n","        #정수 인코딩에 추가할 패딩 길이 연산\n","        padding_count = max_seq_len - len(input_id)\n","        #정수 인코딩,어텐션 마스크에 패딩 추가\n","        input_id = input_id + ([pad_token_id] * padding_count)\n","        attention_mask = attention_mask + ([0] * padding_count)\n","        #세그먼트 인코딩.\n","        token_type_id = [pad_token_id_for_segment] * max_seq_len\n","        # 레이블 패딩.(단, 이 경우는 패딩 토큰의 ID가 -100)\n","        label = labels_ids + ([pad_token_id_for_label] * padding_count)\n","        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\". format(len(input_id), max_seq_len)\n","        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n","        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n","        assert len(label) == max_seq_len, \"Error with labels length {} vs {}\". format(len(label), max_seq_len)\n","\n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        data_labels.append(label)\n","\n","    input_ids = np.array(input_ids, dtype=int)\n","    attention_masks = np.array(attention_masks, dtype=int)\n","    token_type_ids = np.array(token_type_ids, dtype=int)\n","    data_labels = np.asarray(data_labels, dtype=np.int32)\n","\n","    return (input_ids, attention_masks, token_type_ids), data_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HeGPKOOq-Cvz"},"outputs":[],"source":["#!pip install transformers\n","#!pip install seqeval"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4725,"status":"ok","timestamp":1693189962724,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"uU45z9Re-Cvz","outputId":"a218273f-68b3-4cc3-f46e-97eba9ba62e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('1', '가락지빵', 'NNG', 'B_FOOD'), ('2', '주문', 'NNP', 'O'), ('3', '하', 'VV', 'O'), ('4', '고', 'EC', 'O'), ('5', '싶', 'VX', 'O'), ('6', '어요', 'EC', 'O')]\n","샘플 크기 : \n"," 65512\n","0번 째 샘플 단어 시퀀스 : \n"," ['가락지빵', '주문', '하', '고', '싶', '어요']\n","0번 째 샘플 bio 태그 : \n"," ['B_FOOD', 'O', 'O', 'O', 'O', 'O']\n","샘플 단어 시퀀스 최대 길이 : 168\n","샘플 단어 시퀀스 평균 길이 : 8.431951398217121\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","#from tensorflow.keras import preprocessing\n","from sklearn.model_selection import train_test_split\n","from transformers import shape_list, BertTokenizer, TFBertModel\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from seqeval.metrics import f1_score, classification_report\n","import tensorflow as tf\n","import urllib.request\n","\n","\n","\n","\n","# 학습용 말뭉치 데이터를 불러옴\n","#corpus = read_file('ner_train.txt')\n","corpus = read_file('mtn_ner_train_fullversion.txt')\n","print(corpus[0])\n","\n","\n","# 말뭉치 데이터에서 단어와 BIO 태그만 불러와 학습용 데이터셋 생성\n","sentences, tags = [], []\n","for t in corpus:\n","    tagged_sentence = []\n","    sentence, bio_tag = [], []\n","    for w in t:\n","        tagged_sentence.append((w[1], w[3]))\n","        sentence.append(w[1])\n","        bio_tag.append(w[3])\n","\n","    sentences.append(sentence)\n","    tags.append(bio_tag)\n","\n","\n","print(\"샘플 크기 : \\n\", len(sentences))\n","print(\"0번 째 샘플 단어 시퀀스 : \\n\", sentences[0])\n","print(\"0번 째 샘플 bio 태그 : \\n\", tags[0])\n","print(\"샘플 단어 시퀀스 최대 길이 :\", max(len(l) for l in sentences))\n","print(\"샘플 단어 시퀀스 평균 길이 :\", (sum(map(len, sentences))/len(sentences)))\n","\n","\n","# 학습 데이터와 테스트 데이터를 8:2의 비율로 분리\n","train_data_sentence, test_data_sentence, train_data_label, test_data_label = train_test_split(sentences, tags,\n","                                                    test_size=.2,\n","                                                    random_state=1234)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1693189979016,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"01a0mu3n-Cv0","outputId":"915246ff-5a47-426d-ad75-23747cdf504c"},"outputs":[{"name":"stdout","output_type":"stream","text":["52409\n","13103\n","52409\n","13103\n","['머스터드', '주문', '오케이', '?']\n","['B_FOOD', 'O', 'O', 'O']\n"]}],"source":["print(len(train_data_sentence))\n","print(len(test_data_label))\n","print(len(train_data_sentence))\n","print(len(test_data_label))\n","print(train_data_sentence[2])\n","print(train_data_label[2])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":290,"status":"ok","timestamp":1693189980787,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"EImPfoDl-Cv0","outputId":"33858092-7594-4784-e749-bbe88ce6a1b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'O': 0, 'B_DT': 1, 'B_FOOD': 2, 'B_LC': 3, 'I': 4, 'B_OG': 5, 'B_PS': 6, 'NNP': 7, 'B_TI': 8}\n","{0: 'O', 1: 'B_DT', 2: 'B_FOOD', 3: 'B_LC', 4: 'I', 5: 'B_OG', 6: 'B_PS', 7: 'NNP', 8: 'B_TI'}\n"]}],"source":["#labels = ['O', 'B_DT','B_FOOD', 'B_LC', 'I', 'B_OG', 'B_PS', 'NNP', 'B_TI', 'PAD']\n","labels = ['O', 'B_DT','B_FOOD', 'B_LC', 'I', 'B_OG', 'B_PS', 'NNP', 'B_TI']\n","\n","tag_to_index = {tag: index for index, tag in enumerate(labels)}\n","index_to_tag = {index: tag for index, tag in enumerate(labels)}\n","\n","print(tag_to_index)\n","print(index_to_tag)\n","\n","tag_size = len(tag_to_index)\n"]},{"cell_type":"markdown","metadata":{"id":"xnb36bmY-Cv1"},"source":["* 전처리"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["6391f9f4a5ec499bb6fd00b80891c943","0b5716443a4f4094b2081a7f392ad510","7c104e3133964fc78165bd07d14e6872","1055bcabe9c34737813726b58476e108","601c3c1cd33346399638417517d20f18","a4490b43ab3046498f07068f5ea7380a","66ab92f46ec34e3cb3f199df5bd92b7c","bdd4f8a824e045faabc1569213bbc607","da6b99bb57ab42ff99eac1ad17cc72d0","5438a4b689e84b828f0acce41c90c33e","93a62d4c13564d3fbade36d9af3bebff","462138fa325444b3b6ce5ea3c8d4862d","07a680f545584d4e805e58a725b52aa4","d7db647ce69b40039d24259c1b4e0e6a","2e3b2aee562a485b9ee1c7c97f1a3b9c","52cc3b97b9ee45d98eaec82659203895","6364d13b2ac9492f820def2bfddebc10","09982503e46d4ab7a910c740590d731c","61c6148ceb2c4cfa81059ab00fb3075e","838ed8595fa9440da06d41d0187293b0","d895981246af44faa6544d99a0e9edb2","df2afbe847504ad0bb9beb5d55918838","f284645623c2436389ac0c1421623c48","79ae6aa86be4457f9966c79874aaf051","055df3db5722438a8458a8226a187856","3299fcd552524c94bf29af41eebd3808","cf42118225784334a016dde5fb814164","201b44bec5b14cdbbfe744018b983d40","17447691906a46c98c8e24db901e3746","e4364e2700314d4b9d8bf58e8d1f32e7","bbf9bf0da5d0420d9701949b5096e3c2","bdc5bbcd96364861a02dee4e75ed95fe","860dab2af6b24a408ef1ffe6fcac4278","2a057df6ed874c118bd884b2b93a8afb","a2ed0a4cebea41ec9732e622484f2df4","e623f622d42f4c2c8a96f9fd0d75e19f","132c7d36476b404ba8b032a7877eb6eb","e67a3758a2ce4201814d640d0227e67a","76364b85f6424d0ca4a12e258c4b4bab","141985b0aaf04b69b94459f536114e1a","f588f46585d2413a810e99ffb918063b","08b1208e240d44b98529f5ce7e2afc21","142f2e19733748cd8a58f801db529db7","c95f8615d5d6421d962d706dd917328f"]},"executionInfo":{"elapsed":1483,"status":"ok","timestamp":1693189984916,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"2YqtrSHc-Cv1","outputId":"1d2b4a0e-a53d-4674-c9db-cf4cf59e54c7"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6391f9f4a5ec499bb6fd00b80891c943","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"462138fa325444b3b6ce5ea3c8d4862d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f284645623c2436389ac0c1421623c48","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a057df6ed874c118bd884b2b93a8afb","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")"]},{"cell_type":"markdown","metadata":{"id":"vD9e28MC-Cv2"},"source":["* 기존 토큰을 서브 토큰화\n","* 서브토큰에 매칭없는 라벨인코딩은 -100으로 처리\n","* -100은 PAD 처리"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59626,"status":"ok","timestamp":1693190046308,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"HH7Y05PH-Cv2","outputId":"bab5c530-3143-4fdb-f14f-3d338bdf915e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 52409/52409 [00:48<00:00, 1090.96it/s]\n","100%|██████████| 13103/13103 [00:08<00:00, 1602.10it/s]\n"]}],"source":["X_train, y_train = convert_examples_to_features(train_data_sentence, train_data_label, max_seq_len=128, tokenizer=tokenizer)\n","X_test, y_test = convert_examples_to_features(test_data_sentence, test_data_label, max_seq_len=128, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1693190063397,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"yrhSpmuR-Cv2","outputId":"e2c535c8-949a-46e9-d76d-9d1f362110ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["52409\n","52409\n","3\n","13103\n"]}],"source":["print(len(X_train[:][0])) # ids, attention mask, token_type\n","print(len(y_train))\n","print(len(X_test))\n","print(len(y_test))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1693190067397,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"zb2atu8u-Cv2","outputId":"e3045d77-0880-496c-d399-f6a3a6dde62e"},"outputs":[{"name":"stdout","output_type":"stream","text":[" 기 존 원 문 : ['떡국', '미리', '주문', '하', 'ㄹ', '수', '있', '나요', '?']\n"," 기 존 레 이 블 : ['B_FOOD', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","--------------------------------------------------\n"," 토 큰 화 후 원 문 : ['[CLS]', '떡국', '미리', '주문', '하', 'ㄹ', '수', '있', '나요', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"," 토 큰 화 후 레 이 블 : ['[PAD]', 'B_FOOD', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","--------------------------------------------------\n"," 정 수 인 코 딩 결 과 : [    2 27909  5134  4867  1889   185  1295  1513  5444    35     3     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n"," 정 수 인 코 딩 레 이 블 : [-100    2    0    0    0    0    0    0    0    0 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"," -100 -100]\n"]}],"source":["print(' 기 존 원 문 :', train_data_sentence[0])\n","print(' 기 존 레 이 블 :', train_data_label[0])\n","print('-' * 50)\n","print(' 토 큰 화 후 원 문 :', [tokenizer.decode([word]) for word in X_train[0][0]])\n","print(' 토 큰 화 후 레 이 블 :', ['[PAD]' if idx == -100 else index_to_tag[idx] for idx\n","in y_train[0]])\n","print('-' * 50)\n","print(' 정 수 인 코 딩 결 과 :', X_train[0][0])\n","print(' 정 수 인 코 딩 레 이 블 :', y_train[0])"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1693190076312,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"tw6He-Xy-Cv3","outputId":"4d64f6ee-1fb7-4479-f587-c15dc8a37667"},"outputs":[{"name":"stdout","output_type":"stream","text":[" 세 그 먼 트 인 코 딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," 어 텐 션 마 스 크 : [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["print(' 세 그 먼 트 인 코 딩 :', X_train[2][0])\n","print(' 어 텐 션 마 스 크 :', X_train[1][0])"]},{"cell_type":"markdown","metadata":{"id":"JtU8hjds-Cv3"},"source":["* 모델링"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1693190080668,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"DmEMlM-D-Cv3"},"outputs":[],"source":["class TFBertForTokenClassification(tf.keras.Model):\n","\n","    def __init__(self, model_name, num_labels):\n","        super(TFBertForTokenClassification, self).__init__()\n","        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n","        self.classifier = tf.keras.layers.Dense(num_labels, kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),name='classifier')\n","\n","    def call(self, inputs):\n","        input_ids, attention_mask, token_type_ids = inputs\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n","\n","        # 전 체 시 퀀 스 에 대 해 서 분 류 해 야 하 므 로 outputs[0] 임 에 주 의\n","        all_output = outputs[0]\n","        prediction = self.classifier(all_output)\n","\n","        return prediction\n","\n","\n","def compute_loss(labels, logits):\n","    # 다 중 클 래 스 분 류 문 제 에 서 소 프 트 맥 스 함 수 미 사 용 시 from_logits=True 로 설 정 .\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n","    # -100 의 값 을 가 진 정 수 에 대 해 서 는 오 차 를 반 영 하 지 않 도 록 labels 를 수 정 .\n","    active_loss = tf.reshape(labels, (-1,)) != -100\n","    # activa_loss 로 부 터 reduced_logits 과 labels 를 각 각 얻 는 다 .\n","    reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])) , active_loss)\n","    labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n","    return loss_fn(labels, reduced_logits)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26128,"status":"ok","timestamp":1693190172910,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"9yZ--gia-Cv3","outputId":"080025d9-73e0-404b-e60f-26319587cd2f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.88.84.146:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'bert.embeddings.position_ids', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["# TPU 작 동 을 위 한 코 드\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.\n","environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","#strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","strategy = tf.distribute.TPUStrategy(resolver)\n","\n","with strategy.scope():\n","    model = TFBertForTokenClassification(\"klue/bert-base\", num_labels=tag_size)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","    model.compile(optimizer=optimizer, loss=compute_loss)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":302,"status":"ok","timestamp":1693190177244,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"IdAHtRpL-Cv3"},"outputs":[],"source":["class F1score(tf.keras.callbacks.Callback):\n","    def __init__(self, X_test, y_test):\n","        self.X_test = X_test\n","        self.y_test = y_test\n","\n","\n","    def sequences_to_tags(self, label_ids, pred_ids):\n","        label_list = []\n","        pred_list = []\n","\n","        for i in range(0, len(label_ids)):\n","            label_tag = []\n","            pred_tag = []\n","            # 레 이 블 의 값 이 -100 인 경 우 는 F1 score 계 산 시 에 도 제 외\n","            # ex) 레 이 블 디 코 딩 과 정\n","            # label_index : [1 -100 2 -100] ===> [1 2] ===> label_tag : [PER-B PER-I]\n","            for label_index, pred_index in zip(label_ids[i], pred_ids[i]):\n","                if label_index != -100:\n","                    label_tag.append(index_to_tag[label_index])\n","                    pred_tag.append(index_to_tag[pred_index])\n","            label_list.append(label_tag)\n","            pred_list.append(pred_tag)\n","        return label_list, pred_list\n","\n","    # 에 포 크 가 끝 날 때 마 다 실 행 되 는 함 수 }\n","    def on_epoch_end(self, epoch, logs={}):\n","        y_predicted = self.model.predict(self.X_test)\n","        y_predicted = np.argmax(y_predicted, axis = 2)\n","        label_list, pred_list = self.sequences_to_tags(self.y_test, y_predicted)\n","        score = f1_score(label_list, pred_list, suffix=True)\n","        print(' - f1: {:04.2f}'.format(score * 100))\n","        print(classification_report(label_list, pred_list, suffix=True))"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1693190180904,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"o4ophyLY-Cv3"},"outputs":[],"source":["f1_score_report = F1score(X_test, y_test)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":553631,"status":"ok","timestamp":1693190739322,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"Ztca1fkw-Cv4","outputId":"d367790e-8c3a-4b0b-f5a1-1ca0dcd7b1b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"name":"stdout","output_type":"stream","text":["   6/1638 [..............................] - ETA: 1:59 - loss: 1.1329"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_train_batch_end` time: 6.9999s). Check your callbacks.\n"]},{"name":"stdout","output_type":"stream","text":["410/410 [==============================] - 22s 41ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:167: UserWarning: B_DT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:167: UserWarning: B_FOOD seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:167: UserWarning: B_PS seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:167: UserWarning: B_LC seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:167: UserWarning: B_TI seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:167: UserWarning: B_OG seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:167: UserWarning: NNP seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"name":"stdout","output_type":"stream","text":[" - f1: 97.79\n","              precision    recall  f1-score   support\n","\n","         B_D       0.99      0.99      0.99      4588\n","       B_FOO       1.00      1.00      1.00     11685\n","         B_L       0.93      0.95      0.94      1099\n","         B_O       0.81      0.81      0.81       632\n","         B_P       0.95      0.93      0.94       494\n","         B_T       0.94      0.86      0.90        78\n","          NN       1.00      1.00      1.00       297\n","           _       0.82      0.72      0.77       818\n","\n","   micro avg       0.98      0.98      0.98     19691\n","   macro avg       0.93      0.91      0.92     19691\n","weighted avg       0.98      0.98      0.98     19691\n","\n","1638/1638 [==============================] - 244s 96ms/step - loss: 0.0229\n","Epoch 2/3\n","410/410 [==============================] - 9s 21ms/step\n"," - f1: 98.11\n","              precision    recall  f1-score   support\n","\n","         B_D       0.99      0.99      0.99      4588\n","       B_FOO       1.00      1.00      1.00     11685\n","         B_L       0.95      0.96      0.96      1099\n","         B_O       0.90      0.81      0.86       632\n","         B_P       0.94      0.94      0.94       494\n","         B_T       0.91      0.86      0.88        78\n","          NN       1.00      1.00      1.00       297\n","           _       0.81      0.80      0.80       818\n","\n","   micro avg       0.98      0.98      0.98     19691\n","   macro avg       0.94      0.92      0.93     19691\n","weighted avg       0.98      0.98      0.98     19691\n","\n","1638/1638 [==============================] - 142s 87ms/step - loss: 0.0074\n","Epoch 3/3\n","410/410 [==============================] - 11s 23ms/step\n"," - f1: 97.88\n","              precision    recall  f1-score   support\n","\n","         B_D       0.99      0.99      0.99      4588\n","       B_FOO       1.00      1.00      1.00     11685\n","         B_L       0.91      0.97      0.94      1099\n","         B_O       0.83      0.81      0.82       632\n","         B_P       0.98      0.87      0.92       494\n","         B_T       0.93      0.68      0.79        78\n","          NN       1.00      1.00      1.00       297\n","           _       0.83      0.81      0.82       818\n","\n","   micro avg       0.98      0.98      0.98     19691\n","   macro avg       0.93      0.89      0.91     19691\n","weighted avg       0.98      0.98      0.98     19691\n","\n","1638/1638 [==============================] - 152s 93ms/step - loss: 0.0058\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7883e1c3cb20>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X_train, y_train, epochs=3, batch_size=32, callbacks = [f1_score_report])"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":5620,"status":"ok","timestamp":1693190986647,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"jZbwaP72B45J"},"outputs":[],"source":["# model save\n","model.save_weights('ner_model(bert)_use_cpsdic_mtndic_mtndat.h5')"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":263,"status":"ok","timestamp":1693191186401,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"Fvgc0jt2-Cv4"},"outputs":[],"source":["def convert_examples_to_features_for_prediction(examples, max_seq_len, tokenizer,pad_token_id_for_segment=0,pad_token_id_for_label=-100):\n","    cls_token = tokenizer.cls_token\n","    sep_token = tokenizer.sep_token\n","    pad_token_id = tokenizer.pad_token_id\n","\n","    input_ids, attention_masks, token_type_ids, label_masks = [], [], [], []\n","    for example in tqdm(examples):\n","        tokens = []\n","        label_mask = []\n","        for one_word in example:\n","            # 하 나 의 단 어 에 대 해 서 서 브 워 드 로 토 큰 화\n","            subword_tokens = tokenizer.tokenize(one_word)\n","            tokens.extend(subword_tokens)\n","            # 서 브 워 드 중 첫 번 째 서 브 워 드 를 제 외 하 고 그 뒤 의 서 브 워 드 들 은 -100 으 로 채 운 다 .\n","            label_mask.extend([0]+ [pad_token_id_for_label] * (len(subword_tokens)- 1))\n","        # [CLS] 와 [SEP] 를 후 에 추 가 할 것 을 고 려 하 여 최 대 길 이 를 초 과 하 는 샘 플 의 경우 max_seq_len - 2 의 길 이 로 변 환 .\n","        # ex) max_seq_len = 64 라 면 길 이 가 62 보 다 긴 샘 플 은 뒷 부 분 을 자 르 고 길 이 62 로 변 환 .\n","        special_tokens_count = 2\n","        if len(tokens) > max_seq_len - special_tokens_count:\n","            tokens = tokens[:(max_seq_len - special_tokens_count)]\n","            label_mask = label_mask[:(max_seq_len - special_tokens_count)]\n","        # [SEP] 를 추 가 하 는 코 드\n","        # 1. 토 큰 화 결 과 의 맨 뒷 부 분 에 [SEP] 토 큰 추 가\n","        # 2. 레 이 블 에 도 맨 뒷 부 분 에 -100 추 가 .\n","        tokens += [sep_token]\n","        label_mask += [pad_token_id_for_label]\n","        # [CLS] 를 추 가 하 는 코 드\n","        # 1. 토 큰 화 결 과 의 앞 부 분 에 [CLS] 토 큰 추 가\n","        # 2. 레 이 블 의 맨 앞 부 분 에 도 -100 추 가 .\n","        tokens = [cls_token] + tokens\n","        label_mask = [pad_token_id_for_label] + label_mask\n","        # 정 수 인 코 딩\n","        input_id = tokenizer.convert_tokens_to_ids(tokens)\n","        # 어 텐 션 마 스 크 생 성\n","        attention_mask = [1] * len(input_id)\n","        # 정 수 인 코 딩 에 추 가 할 패 딩 길 이 연 산\n","        padding_count = max_seq_len - len(input_id)\n","        # 정 수 인 코 딩 , 어 텐 션 마 스 크 에 패 딩 추 가\n","        input_id = input_id + ([pad_token_id] * padding_count)\n","        attention_mask = attention_mask + ([0] * padding_count)\n","        # 세 그 먼 트 인 코 딩 .\n","        token_type_id = [pad_token_id_for_segment] * max_seq_len\n","        # 레 이 블 패 딩 . (단 , 이 경 우 는 패 딩 토 큰 의 ID 가 -100)\n","\n","        label_mask = label_mask + ([pad_token_id_for_label] * padding_count)\n","\n","        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n","        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n","        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n","        assert len(label_mask) == max_seq_len, \"Error with labels length {} vs {}\".format(len(label_mask), max_seq_len)\n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        label_masks.append(label_mask)\n","\n","    input_ids = np.array(input_ids, dtype=int)\n","    attention_masks = np.array(attention_masks, dtype=int)\n","    token_type_ids = np.array(token_type_ids, dtype=int)\n","    label_masks = np.asarray(label_masks, dtype=np.int32)\n","\n","    return (input_ids, attention_masks, token_type_ids), label_masks"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693191231994,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"QbZ1m4aXDzGZ","outputId":"28b731eb-4fb8-44dd-f52f-aae3b9eda6d6"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:00<00:00, 1199.88it/s]\n"]}],"source":["X_pred, label_masks = convert_examples_to_features_for_prediction(\n","test_data_sentence[:5], max_seq_len=128, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1693191257458,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"S3X1VXGWD_lJ","outputId":"ef62cd5c-4e11-472d-e11d-093d4eb6df4e"},"outputs":[{"name":"stdout","output_type":"stream","text":[" 기 존 원 문 : ['금주', '6시', '40분', '단디', '먹', '고', '싶', '어요']\n","--------------------------------------------------\n"," 토 큰 화 후 원 문 : ['[CLS]', '금주', '6', '##시', '40', '##분', '단', '##디', '먹', '고', '싶', '어요', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"," 레 이 블 마 스 크 : ['[PAD]', '[FIRST]', '[FIRST]', '[PAD]', '[FIRST]', '[PAD]', '[FIRST]', '[PAD]', '[FIRST]', '[FIRST]', '[FIRST]', '[FIRST]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"]}],"source":["print(' 기 존 원 문 :', test_data_sentence[0])\n","print('-' * 50)\n","print(' 토 큰 화 후 원 문 :', [tokenizer.decode([word]) for word in X_pred[0][0]])\n","print(' 레 이 블 마 스 크 :', ['[PAD]' if idx == -100 else '[FIRST]' for idx in label_masks[0]])"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":283,"status":"ok","timestamp":1693191349817,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"yZe_bcysEGbp"},"outputs":[],"source":["def ner_prediction(examples, max_seq_len, tokenizer):\n","\n","    examples = [sent.split() for sent in examples]\n","    X_pred, label_masks = convert_examples_to_features_for_prediction(examples,\n","    max_seq_len=128, tokenizer=tokenizer)\n","    y_predicted = model.predict(X_pred)\n","    y_predicted = np.argmax(y_predicted, axis = 2)\n","    pred_list = []\n","    result_list = []\n","\n","    for i in range(0, len(label_masks)):\n","        pred_tag = []\n","        # ex) 모 델 의 예 측 값 디 코 딩 과 정\n","        # 예 측 값 (y_predicted) 에 서 레 이 블 마 스 크 (label_masks) 의 값 이 -100 인 동 일 위 치 의        값 을 삭 제\n","        # label_masks : [-100 0 -100 0 -100]\n","        # y_predicted : [ 0 1 0 2 0 ] ==> [1 2] ==> 최 종 예 측 (pred_tag) : [PERB    PER-I]\n","        for label_index, pred_index in zip(label_masks[i], y_predicted[i]):\n","            if label_index != -100:\n","                pred_tag.append(index_to_tag[pred_index])\n","            pred_list.append(pred_tag)\n","    for example, pred in zip(examples, pred_list):\n","        one_sample_result = []\n","        for one_word, label_token in zip(example, pred):\n","            one_sample_result.append((one_word, label_token))\n","        result_list.append(one_sample_result)\n","    return result_list"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1399,"status":"ok","timestamp":1693191650142,"user":{"displayName":"Swamp Runner","userId":"05016847915266397542"},"user_tz":-540},"id":"VtZFKVUlEcVU","outputId":"f367a614-c4ff-465e-b2a1-d41ab196cde2"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 2336.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 833ms/step\n"]},{"data":{"text/plain":["[[('설악산,', 'B_LC'), ('오색리구간', 'B_LC')]]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["#sent1 = ' 오 리 온 스 는 리 그 최 정 상 급 포 인 트 가 드 김 동 훈 을 앞 세 우 는 빠 른 공 수 전 환 이 돋보 이 는 팀 이 다 '\n","#sent2 = ' 하 이 신 사 에 속 한 섬 들 도 위 로 솟 아 있 는 데 타 인 은 살 고 있 어 요 '\n","sent1 = '설악산, 오색리구간'\n","#sent1 = '10시 10분'\n","test_samples = [sent1]\n","result_list = ner_prediction(test_samples, max_seq_len=128, tokenizer=tokenizer)\n","result_list"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"055df3db5722438a8458a8226a187856":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4364e2700314d4b9d8bf58e8d1f32e7","max":289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bbf9bf0da5d0420d9701949b5096e3c2","value":289}},"07a680f545584d4e805e58a725b52aa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6364d13b2ac9492f820def2bfddebc10","placeholder":"​","style":"IPY_MODEL_09982503e46d4ab7a910c740590d731c","value":"Downloading (…)cial_tokens_map.json: 100%"}},"08b1208e240d44b98529f5ce7e2afc21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09982503e46d4ab7a910c740590d731c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b5716443a4f4094b2081a7f392ad510":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4490b43ab3046498f07068f5ea7380a","placeholder":"​","style":"IPY_MODEL_66ab92f46ec34e3cb3f199df5bd92b7c","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"1055bcabe9c34737813726b58476e108":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5438a4b689e84b828f0acce41c90c33e","placeholder":"​","style":"IPY_MODEL_93a62d4c13564d3fbade36d9af3bebff","value":" 248k/248k [00:00&lt;00:00, 3.14MB/s]"}},"132c7d36476b404ba8b032a7877eb6eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_142f2e19733748cd8a58f801db529db7","placeholder":"​","style":"IPY_MODEL_c95f8615d5d6421d962d706dd917328f","value":" 425/425 [00:00&lt;00:00, 10.0kB/s]"}},"141985b0aaf04b69b94459f536114e1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"142f2e19733748cd8a58f801db529db7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17447691906a46c98c8e24db901e3746":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"201b44bec5b14cdbbfe744018b983d40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a057df6ed874c118bd884b2b93a8afb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2ed0a4cebea41ec9732e622484f2df4","IPY_MODEL_e623f622d42f4c2c8a96f9fd0d75e19f","IPY_MODEL_132c7d36476b404ba8b032a7877eb6eb"],"layout":"IPY_MODEL_e67a3758a2ce4201814d640d0227e67a"}},"2e3b2aee562a485b9ee1c7c97f1a3b9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d895981246af44faa6544d99a0e9edb2","placeholder":"​","style":"IPY_MODEL_df2afbe847504ad0bb9beb5d55918838","value":" 125/125 [00:00&lt;00:00, 3.57kB/s]"}},"3299fcd552524c94bf29af41eebd3808":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdc5bbcd96364861a02dee4e75ed95fe","placeholder":"​","style":"IPY_MODEL_860dab2af6b24a408ef1ffe6fcac4278","value":" 289/289 [00:00&lt;00:00, 4.61kB/s]"}},"462138fa325444b3b6ce5ea3c8d4862d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07a680f545584d4e805e58a725b52aa4","IPY_MODEL_d7db647ce69b40039d24259c1b4e0e6a","IPY_MODEL_2e3b2aee562a485b9ee1c7c97f1a3b9c"],"layout":"IPY_MODEL_52cc3b97b9ee45d98eaec82659203895"}},"52cc3b97b9ee45d98eaec82659203895":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5438a4b689e84b828f0acce41c90c33e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"601c3c1cd33346399638417517d20f18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c6148ceb2c4cfa81059ab00fb3075e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6364d13b2ac9492f820def2bfddebc10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6391f9f4a5ec499bb6fd00b80891c943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b5716443a4f4094b2081a7f392ad510","IPY_MODEL_7c104e3133964fc78165bd07d14e6872","IPY_MODEL_1055bcabe9c34737813726b58476e108"],"layout":"IPY_MODEL_601c3c1cd33346399638417517d20f18"}},"66ab92f46ec34e3cb3f199df5bd92b7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76364b85f6424d0ca4a12e258c4b4bab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79ae6aa86be4457f9966c79874aaf051":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_201b44bec5b14cdbbfe744018b983d40","placeholder":"​","style":"IPY_MODEL_17447691906a46c98c8e24db901e3746","value":"Downloading (…)okenizer_config.json: 100%"}},"7c104e3133964fc78165bd07d14e6872":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdd4f8a824e045faabc1569213bbc607","max":248477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da6b99bb57ab42ff99eac1ad17cc72d0","value":248477}},"838ed8595fa9440da06d41d0187293b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"860dab2af6b24a408ef1ffe6fcac4278":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93a62d4c13564d3fbade36d9af3bebff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2ed0a4cebea41ec9732e622484f2df4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76364b85f6424d0ca4a12e258c4b4bab","placeholder":"​","style":"IPY_MODEL_141985b0aaf04b69b94459f536114e1a","value":"Downloading (…)lve/main/config.json: 100%"}},"a4490b43ab3046498f07068f5ea7380a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbf9bf0da5d0420d9701949b5096e3c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdc5bbcd96364861a02dee4e75ed95fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdd4f8a824e045faabc1569213bbc607":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c95f8615d5d6421d962d706dd917328f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf42118225784334a016dde5fb814164":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7db647ce69b40039d24259c1b4e0e6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61c6148ceb2c4cfa81059ab00fb3075e","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_838ed8595fa9440da06d41d0187293b0","value":125}},"d895981246af44faa6544d99a0e9edb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da6b99bb57ab42ff99eac1ad17cc72d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df2afbe847504ad0bb9beb5d55918838":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4364e2700314d4b9d8bf58e8d1f32e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e623f622d42f4c2c8a96f9fd0d75e19f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f588f46585d2413a810e99ffb918063b","max":425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08b1208e240d44b98529f5ce7e2afc21","value":425}},"e67a3758a2ce4201814d640d0227e67a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f284645623c2436389ac0c1421623c48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79ae6aa86be4457f9966c79874aaf051","IPY_MODEL_055df3db5722438a8458a8226a187856","IPY_MODEL_3299fcd552524c94bf29af41eebd3808"],"layout":"IPY_MODEL_cf42118225784334a016dde5fb814164"}},"f588f46585d2413a810e99ffb918063b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}

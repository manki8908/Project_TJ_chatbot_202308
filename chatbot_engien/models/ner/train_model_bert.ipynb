{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 크기 : \n",
      " 65512\n",
      "0번 째 샘플 단어 시퀀스 : \n",
      " ['가락지빵', '주문', '하', '고', '싶', '어요']\n",
      "0번 째 샘플 bio 태그 : \n",
      " ['B_FOOD', 'O', 'O', 'O', 'O', 'O']\n",
      "샘플 단어 시퀀스 최대 길이 : 168\n",
      "샘플 단어 시퀀스 평균 길이 : 8.431951398217121\n",
      "BIO 태그 사전 크기 : 10\n",
      "단어 사전 크기 : 17869\n",
      "index_to_ner {1: 'O', 2: 'B_DT', 3: 'B_FOOD', 4: 'B_LC', 5: 'I', 6: 'B_OG', 7: 'B_PS', 8: 'NNP', 9: 'B_TI', 0: 'PAD'}\n",
      "학습 샘플 시퀀스 형상 :  (52409, 40)\n",
      "학습 샘플 레이블 형상 :  (52409, 40, 10)\n",
      "테스트 샘플 시퀀스 형상 :  (13103, 40)\n",
      "테스트 샘플 레이블 형상 :  (13103, 40, 10)\n",
      "410/410 [==============================] - 149s 351ms/step - loss: 0.1210 - accuracy: 0.9672\n",
      "410/410 [==============================] - 15s 34ms/step - loss: 0.0508 - accuracy: 0.9832\n",
      "평가 결과 :  0.9831815361976624\n",
      "410/410 [==============================] - 14s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_DT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_FOOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_LC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_PS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_TI seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_OG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NNP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Python38\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NP       1.00      1.00      1.00       297\n",
      "           _       0.45      0.38      0.41       640\n",
      "         _DT       0.99      0.99      0.99     13466\n",
      "       _FOOD       1.00      1.00      1.00     11685\n",
      "         _LC       0.94      0.88      0.91      1747\n",
      "         _OG       0.46      0.40      0.43       464\n",
      "         _PS       0.64      0.04      0.08       396\n",
      "         _TI       0.00      0.00      0.00        65\n",
      "\n",
      "   micro avg       0.97      0.95      0.96     28760\n",
      "   macro avg       0.69      0.59      0.60     28760\n",
      "weighted avg       0.97      0.95      0.95     28760\n",
      "\n",
      "F1-score: 96.3%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from utils.Preprocess import Preprocess\n",
    "\n",
    "# 학습 파일 불러오기\n",
    "def read_file(file_name):\n",
    "    sents = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for idx, l in enumerate(lines):\n",
    "            if l[0] == ';' and lines[idx + 1][0] == '$':\n",
    "                this_sent = []\n",
    "            elif l[0] == '$' and lines[idx - 1][0] == ';':\n",
    "                continue\n",
    "            elif l[0] == '\\n':\n",
    "                sents.append(this_sent)\n",
    "            else:\n",
    "                this_sent.append(tuple(l.split()))\n",
    "    return sents\n",
    "\n",
    "\n",
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer, pad_token_id_for_segment=0,\n",
    "                                     pad_token_id_for_label=-100):\n",
    "    cls_token = tokenizer.cls_token\n",
    "    sep_token = tokenizer.sep_token\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "\n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)): \n",
    "        tokens = []\n",
    "        labels_ids = []\n",
    "        for one_word, label_token in zip(example, label):\n",
    "            #하나의 단어에 대해서 서브워드로 토큰화 subword_tokens = tokenizer.tokenize(one_word)\n",
    "            tokens.extend(subword_tokens)\n",
    "            #서브워드 중 첫번째 서브워드만 개체명 레이블을 부여하고 그 외에는 -100으로 채운다.\n",
    "            labels_ids.extend([tag_to_index[label_token]]+ [pad_token_id_for_label] * (len(subword_tokens) - 1))\n",
    "            #[CLS]와[SEP]를 후에 추가할 것을 고려하여 최대 길이를 초과하는 샘플의 경 우 max_seq_len-2의 길이로 변환.\n",
    "            #ex)max_seq_len=64라면 길이가62보다 긴 샘플은 뒷 부분을 자르고 길이 62로 변환.\n",
    "            special_tokens_count = 2\n",
    "            if len(tokens) > max_seq_len - special_tokens_count:\n",
    "                tokens = tokens[:(max_seq_len - special_tokens_count)]\n",
    "                labels_ids = labels_ids[:(max_seq_len - special_tokens_count)]\n",
    "            #[SEP]를 추가하는 코드\n",
    "            #1.토큰화 결과의 맨 뒷 부분에[SEP]토큰 추가 #2. 레이블에도 맨 뒷 부분에 -100 추가.\n",
    "            tokens += [sep_token]\n",
    "            labels_ids += [pad_token_id_for_label]\n",
    "            #[CLS]를 추가하는 코드\n",
    "            #1. 토큰화 결과의 앞 부분에 [CLS] 토큰 추가\n",
    "            #2. 레이블의 맨 앞 부분에도 -100 추가.\n",
    "            tokens = [cls_token] + tokens\n",
    "            labels_ids = [pad_token_id_for_label] + labels_ids\n",
    "            #정수 인코딩\n",
    "            input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "            #어텐션 마스크 생성\n",
    "            attention_mask = [1] * len(input_id)\n",
    "            #정수 인코딩에 추가할 패딩 길이 연산 padding_count = max_seq_len - len(input_id)\n",
    "            #정수 인코딩,어텐션 마스크에 패딩 추가\n",
    "            input_id = input_id + ([pad_token_id] * padding_count) attention_mask = attention_mask + ([0] * padding_count)\n",
    "            #세그먼트 인코딩.\n",
    "            token_type_id = [pad_token_id_for_segment] * max_seq_len\n",
    "            # 레이블 패딩.(단, 이 경우는 패딩 토큰의 ID가 -100)\n",
    "            label = labels_ids + ([pad_token_id_for_label] * padding_count)\n",
    "            assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\". format(len(input_id), max_seq_len)\n",
    "            assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "            assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "            assert len(label) == max_seq_len, \"Error with labels length {} vs {}\". format(len(label), max_seq_len)\n",
    "\n",
    "            input_ids.append(input_id)\n",
    "            attention_masks.append(attention_mask)\n",
    "            token_type_ids.append(token_type_id)\n",
    "            data_labels.append(label)\n",
    "\n",
    "            input_ids = np.array(input_ids, dtype=int) \n",
    "            attention_masks = np.array(attention_masks, dtype=int) \n",
    "            token_type_ids = np.array(token_type_ids, dtype=int) \n",
    "            data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "            return (input_ids, attention_masks, token_type_ids), data_labels\n",
    "\n",
    "\n",
    "\n",
    "p = Preprocess(word2index_dic='../../train_tools/dict/chatbot_dict.bin',\n",
    "               #userdic='../../utils/user_dic.tsv')\n",
    "               userdic='../../utils/mtn_user_dict.tsv')\n",
    "\n",
    "# 학습용 말뭉치 데이터를 불러옴\n",
    "#corpus = read_file('ner_train.txt')\n",
    "corpus = read_file('mtn_ner_train_fullversion.txt')\n",
    "print(corpus[0])\n",
    "\n",
    "\n",
    "# 말뭉치 데이터에서 단어와 BIO 태그만 불러와 학습용 데이터셋 생성\n",
    "sentences, tags = [], []\n",
    "for t in corpus:\n",
    "    tagged_sentence = []\n",
    "    sentence, bio_tag = [], []\n",
    "    for w in t:\n",
    "        tagged_sentence.append((w[1], w[3]))\n",
    "        sentence.append(w[1])\n",
    "        bio_tag.append(w[3])\n",
    "    \n",
    "    sentences.append(sentence)\n",
    "    tags.append(bio_tag)\n",
    "\n",
    "\n",
    "print(\"샘플 크기 : \\n\", len(sentences))\n",
    "print(\"0번 째 샘플 단어 시퀀스 : \\n\", sentences[0])\n",
    "print(\"0번 째 샘플 bio 태그 : \\n\", tags[0])\n",
    "print(\"샘플 단어 시퀀스 최대 길이 :\", max(len(l) for l in sentences))\n",
    "print(\"샘플 단어 시퀀스 평균 길이 :\", (sum(map(len, sentences))/len(sentences)))\n",
    "\n",
    "\n",
    "\n",
    "# 학습 데이터와 테스트 데이터를 8:2의 비율로 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train,\n",
    "                                                    test_size=.2,\n",
    "                                                    random_state=1234)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 정의 (Bi-LSTM)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=30, input_length=max_len, mask_zero=True))\n",
    "\n",
    "model.add(TFBertModel.from_pretrained(model_name, from_pt=True))\n",
    "model.add(tf.keras.layers.Dense(num_labels,\n",
    "                                            kernel_initializer=tf.keras.\n",
    "                                                initializers.TruncatedNormal\n",
    "                                                (0.02),\n",
    "                                            name='classifier'))\n",
    "\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=1)\n",
    "\n",
    "print(\"평가 결과 : \", model.evaluate(x_test, y_test)[1])\n",
    "model.save('ner_model_use_cpsdic_mtndic_mtndat.h5')\n",
    "\n",
    "\n",
    "# 시퀀스를 NER 태그로 변환\n",
    "def sequences_to_tag(sequences):  # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n",
    "    result = []\n",
    "    for sequence in sequences:  # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "        temp = []\n",
    "        for pred in sequence:  # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
    "            pred_index = np.argmax(pred)  # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))  # 'PAD'는 'O'로 변경\n",
    "        result.append(temp)\n",
    "    return result\n",
    "\n",
    "\n",
    "# f1 스코어 계산을 위해 사용\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "# 테스트 데이터셋의 NER 예측\n",
    "y_predicted = model.predict(x_test)\n",
    "pred_tags = sequences_to_tag(y_predicted) # 예측된 NER\n",
    "test_tags = sequences_to_tag(y_test)    # 실제 NER\n",
    "\n",
    "# F1 평가 결과\n",
    "print(classification_report(test_tags, pred_tags))\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== load data shape\n",
      "(868, 49, 20)\n",
      "(868, 49, 2)\n",
      "================================================== split data shape\n",
      "(109, 49, 20)\n",
      "(109, 49, 2)\n",
      "(61, 49, 20)\n",
      "(61, 49, 2)\n",
      "결측 합계:  1\n",
      "shape of after drop\n",
      "(108, 49, 20)\n",
      "(108, 49, 2)\n",
      "결측 합계:  5\n",
      "shape of after drop\n",
      "(56, 49, 20)\n",
      "(56, 49, 2)\n",
      "================================================== drop data shape\n",
      "(108, 48, 6)\n",
      "(108, 48, 2)\n",
      "(56, 48, 6)\n",
      "(56, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "from tensorflow.keras import Input, Model, callbacks\n",
    "from tensorflow.keras.utils import plot_model as plm\n",
    "from tensorflow.keras.activations import swish\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tcn import TCN, tcn_full_summary\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../MODL/INC/')\n",
    "from data_load import data_load\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Set configure\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Data set\n",
    "\n",
    "element = 'ALLV'\n",
    "name_list = \"./SHEL/namelist.input\"\n",
    "\n",
    "hp_lr = 0.009\n",
    "hp_pd = 'same'\n",
    "hp_ns = 1\n",
    "hp_dl = [1,2,4,8,16,32,48]\n",
    "hp_ldl = hp_dl[-1] # last dilation factor to make name of save model\n",
    "hp_bn = True\n",
    "hp_nf = 80\n",
    "hp_dr = 0.07\n",
    "hp_ks = 6\n",
    "\n",
    "input_size = 6\n",
    "output_size = 2\n",
    "num_fct = 48\n",
    "batch_size = 8\n",
    "n_iter_search = 20\n",
    "num_epoch = 600\n",
    "dev_stn_id = 47105\n",
    "tran_data_per = \"2101_2104_2201_2204\"\n",
    "\n",
    "exp_name = \"CNTL\"\n",
    "csv_outdir = './DAOU/LOSS/' + exp_name + '/'\n",
    "model_outdir = './DAOU/MODL/' + exp_name + '/'\n",
    "scalr_outdir = './DAOU/SCAL/' + exp_name + '/'\n",
    "gifd_outdir = './GIFD/' + exp_name + '/'\n",
    "log_outdir = './DAOU/LOGF/' + exp_name + '/'\n",
    "\n",
    "\n",
    "if os.path.exists(csv_outdir) != True: os.makedirs(csv_outdir)\n",
    "if os.path.exists(model_outdir) != True: os.makedirs(model_outdir)\n",
    "if os.path.exists(scalr_outdir) != True: os.makedirs(scalr_outdir)\n",
    "if os.path.exists(gifd_outdir) != True: os.makedirs(gifd_outdir)\n",
    "if os.path.exists(log_outdir) != True: os.makedirs(log_outdir)\n",
    "\n",
    "\n",
    "nwp_file = \"../DAIO/nwp_data_47105\"\n",
    "obs_file = \"../DAIO/obs_data_47105\"\n",
    "\n",
    "sel_dm_nwp_train, sel_dm_nwp_test, dm_obs_train, dm_obs_test = data_load(nwp_file, obs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Final training data shape\n",
      "<class 'numpy.ndarray'>\n",
      "tran nwp :  (108, 48, 6)\n",
      "tran obs :  (108, 48, 2)\n",
      "test nwp :  (56, 48, 6)\n",
      "test obs :  (56, 48, 2)\n",
      "in split, re_nwp_stn shape:  (108, 48, 6)\n",
      "tran nwp shape:  (86, 48, 6) tran obs shape:  (86, 48, 2)\n",
      "vald nwp shape:  (22, 48, 6) vald obs shape:  (22, 48, 2)\n",
      "plotting KDE .. \n",
      "tran_y shape:  (86, 48, 2)\n",
      "vald_y shape:  (22, 48, 2)\n",
      "test_y shape:  (56, 48, 2)\n",
      "tran_obs shape: (86, 48, 1)\n",
      "vald_obs shape: (22, 48, 1)\n",
      "test_obs shape: (56, 48, 1)\n",
      "calc from numpy\n",
      "tran_x_median: 0.5014880952380952\n",
      "vald_x_median: 0.4680059523809524\n",
      "test_x_median: 0.5282738095238095\n",
      "./GIFD/CNTL/KDE_ecmw_tran_vald_obs_uuu2101_2104_2201_2204_47105\n",
      "tran_obs shape: (86, 48, 1)\n",
      "vald_obs shape: (22, 48, 1)\n",
      "test_obs shape: (56, 48, 1)\n",
      "calc from numpy\n",
      "tran_x_median: 0.4540816326530611\n",
      "vald_x_median: 0.4447278911564625\n",
      "test_x_median: 0.3801020408163265\n",
      "./GIFD/CNTL/KDE_ecmw_tran_vald_obs_vvv2101_2104_2201_2204_47105\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, '../MODL/INC/')\n",
    "from data_scaling import data_scaling\n",
    "from step_sampling_for_date import step_sampling_for_date\n",
    "from hist_and_kde_for_split import hist_and_kde_for_split, hist_and_kde_for_split_UV\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Model & Scaler list load\n",
    "\n",
    "output_size = 2\n",
    "tran_rate = 0.8\n",
    "nbin = 10\n",
    "random_seed = 1\n",
    "exp_name = \"test\"\n",
    "\n",
    "\n",
    "\n",
    "nor_dm_nwp_train, nor_dm_nwp_train, nor_dm_nwp_test, nor_dm_nwp_test, nor_dm_obs_train, nor_dm_obs_train,nor_dm_obs_test,nor_dm_obs_test = data_scaling(output_size, tran_rate, nbin, random_seed, exp_name, sel_dm_nwp_train, sel_dm_nwp_test,dm_obs_train, dm_obs_test)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. split train --> train/valid for hyper-parameter tuning\n",
    "#tran_x, tran_y, vald_x, vald_y = data_split_5years(re_nwp_stn, re_obs_stn, tran_rate, random_seed) \n",
    "tran_x, tran_y, vald_x, vald_y = step_sampling_for_date(nor_dm_nwp_train, nor_dm_obs_train, tran_rate, nbin, random_seed)\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Plot tran valid\n",
    "#var_name = ['NDNSW_surface', 'UGRD_10m', 'VGRD_10m', 'RH_1_5ma', 'MAXGUST_0m', 'PRMSL_meansealevel', \"OBS\"]\n",
    "hist_and_kde_for_split_UV(exp_name, tran_data_per, dev_stn_id, gifd_outdir, tran_y, vald_y, nor_dm_obs_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# .. Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# .. Read stn list\n",
    "\n",
    "# .. all station\n",
    "test_x_all = np.ndarray( shape=( len(num_his), 31, num_fct, len(model_list), input_size ), dtype=np.float32 )\n",
    "test_y_all = np.ndarray( shape=( len(num_his), 31, num_fct, len(model_list), output_size ), dtype=np.float32 )\n",
    "pred_test_all = np.ndarray( shape=( len(num_his), 31, num_fct, len(model_list), output_size ), dtype=np.float32 )\n",
    "\n",
    "\n",
    "pred_test_all.fill(np.nan)\n",
    "test_x_all.fill(np.nan)\n",
    "test_y_all.fill(np.nan)\n",
    "\n",
    "\n",
    "#for i in range(5):    # for models\n",
    "for i in range(len(model_list)):    # for models\n",
    "#for i in range(dev_stn_id.shape[0]):    # for some stations\n",
    "#for i in [100, 200, 300 ]:    # for some stations\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # .. Run LSTM forecast \n",
    "\n",
    "    if len(model_list)!=1:\n",
    "       run_stn_id = mod_stn_id[i]\n",
    "    else:\n",
    "       run_stn_id = mod_stn_id\n",
    "\n",
    "    print ( \"=================== Start {} station\".format(run_stn_id) )\n",
    "\n",
    "    # .. clear model\n",
    "    K.clear_session()\n",
    "\n",
    "    # .. Load model \n",
    "    model_name = load_dir + mdl_dir + model_list[i]\n",
    "    try:\n",
    "       print (\"load_model: \", model_list[i])\n",
    "       model = load_model(model_name, custom_objects={'TCN':TCN} )\n",
    "    except:\n",
    "       print (\"Error: Could not load \", model_name)\n",
    "       continue       \n",
    "   \n",
    "\n",
    "    # .. Load scaler\n",
    "    print (\"load_scaler:\", nwp_scaler_list[i])\n",
    "    print (\"load_scaler:\", obs_scaler_list[i])\n",
    "    nwp_scaler = joblib.load(load_dir + scl_dir + nwp_scaler_list[i])\n",
    "    obs_scaler = joblib.load(load_dir + scl_dir + obs_scaler_list[i])\n",
    "\n",
    "\n",
    "    for k in range(len(test_name)):  # for days\n",
    "    #for k in [4]:  # for days\n",
    "\n",
    "        #-------------------------------------------------------------------------\n",
    "        # .. Data load\n",
    "\n",
    "        print(test_peri_name[k])\n",
    "\n",
    "        test_x, test_y = test_data_load(data_dir, test_peri_name[k], element,\n",
    "                                        input_size, output_size, num_his[k],\n",
    "                                        num_fct, run_stn_id)\n",
    "\n",
    "        test_x = np.swapaxes(test_x,0,1)\n",
    "        #test_x_ori = copy.deepcopy(test_x)\n",
    "        test_y = np.swapaxes(test_y,0,1)\n",
    "\n",
    "\n",
    "        print (\"======= Loaded data shape \")\n",
    "        print (\"test_x shape: \", test_x.shape)\n",
    "        print (\"test_y shape: \", test_y.shape)\n",
    "\n",
    " \n",
    "        # .. load data  \n",
    "        b, s, f = test_x.shape\n",
    "\n",
    "        #---------------------------------------------------------------------\n",
    "        # .. Model run\n",
    "\n",
    "        # .. 2021.02.25 kmk\n",
    "        for j in range(b):\n",
    "\n",
    "            # .. check missing\n",
    "            nwp_count = check_missing_existence(test_x[j,:,:], test_y[j,:,:]) \n",
    "            if nwp_count > 0:\n",
    "               print ( \"------- nwp missing count > 0, pass \", j, '  day' )\n",
    "               continue\n",
    "\n",
    "            # .. normalize\n",
    "            nor_test_x = nwp_scaler.transform(test_x[j:j+1,:,:].reshape(1*s,f))          # scaler input dim=(N,n_feature)\n",
    "            nor_test_y = obs_scaler.transform(test_y[j:j+1,:,:].reshape(1*s,output_size))\n",
    "            nor_test_x = nor_test_x.reshape(1,s,f)\n",
    "            nor_test_y = nor_test_y.reshape(1,s,output_size)\n",
    "\n",
    "            nor_pred_test = model.predict(nor_test_x, batch_size=1)    \n",
    "            inv_pred_test = obs_scaler.inverse_transform(nor_pred_test.reshape(1*s,output_size))\n",
    "            inv_pred_test = inv_pred_test.reshape(s,output_size)\n",
    "\n",
    "            # .. Data save\n",
    "            test_x_all[k,j,:,i,:] = test_x[j,:,:]  # select feature 0\n",
    "            test_y_all[k,j,:,i,:] = test_y[j,:,:]  # select feature 0\n",
    "            pred_test_all[k,j,:,i,:] = inv_pred_test[:,:] # select feature 0\n",
    "\n",
    "\n",
    "#pred_test_all = pred_test_all[:,:,2:-2,:]\n",
    "#test_x_all = test_x_all[:,:,2:-2,:]\n",
    "#test_y_all = test_y_all[:,:,2:-2,:]\n",
    "print (\"-------------- all list fcst complete\")\n",
    "print (\"pred_test_all: \", pred_test_all.shape)\n",
    "print (\"test_x_all: \", test_x_all.shape)\n",
    "print (\"test_y_all: \", test_y_all.shape)\n",
    "\n",
    "#print ( pred_test_all )\n",
    "\n",
    "if each_stn_mod == \"ON\":\n",
    "   np.savez( (prt_outdir + 'tcnm' + '_' + total_test_peri + '_' + find_ep + '_' + find_id), value=pred_test_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'g128' + '_' + total_test_peri + '_' + find_ep + '_' + find_id), value=test_x_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'tobs' + '_' + total_test_peri + '_' + find_ep + '_' + find_id), value=test_y_all, stn_id=mod_stn_id )\n",
    "else:\n",
    "   np.savez( (prt_outdir + 'tcnm' + '_' + total_test_peri + '_' + find_ep ), value=pred_test_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'g128' + '_' + total_test_peri + '_' + find_ep ), value=test_x_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'tobs' + '_' + total_test_peri + '_' + find_ep ), value=test_y_all, stn_id=mod_stn_id )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

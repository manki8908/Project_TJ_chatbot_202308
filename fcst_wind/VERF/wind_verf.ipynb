{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== load data shape\n",
      "(868, 49, 20)\n",
      "(868, 49, 2)\n",
      "================================================== split data shape\n",
      "(109, 49, 20)\n",
      "(109, 49, 2)\n",
      "(61, 49, 20)\n",
      "(61, 49, 2)\n",
      "결측 합계:  1\n",
      "결측 index= [23]\n",
      "shape of after drop\n",
      "(108, 49, 20)\n",
      "(108, 49, 2)\n",
      "결측 합계:  5\n",
      "결측 index= [16, 17, 18, 19, 15]\n",
      "test_nwp missing\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan]]\n",
      "test_obs missing\n",
      "[[ 2.9   3.7   3.3   3.19  2.07  1.97 -0.    1.03  2.4   2.26  3.29  2.16\n",
      "   1.03  3.1   2.44  0.64  1.9   2.4  -0.58 -0.    1.09  1.6   1.97  1.41\n",
      "   0.94  1.5  -0.48 -0.38 -1.5  -1.99 -1.61 -1.4  -0.84  2.82  3.2   2.07\n",
      "   2.54  2.7   2.35  2.6   2.5   2.54  2.73  2.82  3.29  2.73  2.26  2.07\n",
      "   2.8 ]\n",
      " [ 0.94  1.5  -0.48 -0.38 -1.5  -1.99 -1.61 -1.4  -0.84  2.82  3.2   2.07\n",
      "   2.54  2.7   2.35  2.6   2.5   2.54  2.73  2.82  3.29  2.73  2.26  2.07\n",
      "   2.8   2.73  2.91  3.    2.3   3.5   4.5   4.5   4.2   2.3   1.9   0.44\n",
      "  -0.    2.07  0.77 -1.09  1.03 -0.41  2.5   2.6   2.35  5.36  1.86  2.91\n",
      "   3.48]\n",
      " [ 2.8   2.73  2.91  3.    2.3   3.5   4.5   4.5   4.2   2.3   1.9   0.44\n",
      "  -0.    2.07  0.77 -1.09  1.03 -0.41  2.5   2.6   2.35  5.36  1.86  2.91\n",
      "   3.48  3.95  3.19  3.01  4.4   4.04  3.76  3.29  3.6   3.8   3.38  3.29\n",
      "   3.85  3.7   4.5   3.8   3.6   2.9   3.8   4.5   5.1   3.6   2.5   3.4\n",
      "   2.7 ]\n",
      " [ 3.48  3.95  3.19  3.01  4.4   4.04  3.76  3.29  3.6   3.8   3.38  3.29\n",
      "   3.85  3.7   4.5   3.8   3.6   2.9   3.8   4.5   5.1   3.6   2.5   3.4\n",
      "   2.7   2.3   3.9   2.9   3.1   2.8   2.35  3.9   2.1   1.6   1.69  2.5\n",
      "   3.    1.5   2.07  2.07  2.26  2.44  2.07  3.1   3.38  2.73  2.63  2.63\n",
      "   1.4 ]\n",
      " [ 2.35  3.3   3.5   3.3   3.3   2.9   3.4   3.    2.91  2.8   3.5   3.5\n",
      "   3.5   3.4   2.6   2.35  2.44  2.3   2.26  2.35  2.6   3.7   3.6   2.9\n",
      "   2.9   3.7   3.3   3.19  2.07  1.97 -0.    1.03  2.4   2.26  3.29  2.16\n",
      "   1.03  3.1   2.44  0.64  1.9   2.4  -0.58 -0.    1.09  1.6   1.97  1.41\n",
      "   0.94]]\n",
      "shape of after drop\n",
      "(56, 49, 20)\n",
      "(56, 49, 2)\n",
      "================================================== drop data shape\n",
      "(108, 48, 6)\n",
      "(108, 48, 2)\n",
      "(56, 48, 6)\n",
      "(56, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "from tensorflow.keras import Input, Model, callbacks\n",
    "from tensorflow.keras.utils import plot_model as plm\n",
    "from tensorflow.keras.activations import swish\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tcn import TCN, tcn_full_summary\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../MODL/INC/')\n",
    "from data_load import data_load\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Set configure\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Data set\n",
    "\n",
    "element = 'ALLV'\n",
    "name_list = \"./SHEL/namelist.input\"\n",
    "\n",
    "hp_lr = 0.009\n",
    "hp_pd = 'same'\n",
    "hp_ns = 1\n",
    "hp_dl = [1,2,4,8,16,32,48]\n",
    "hp_ldl = hp_dl[-1] # last dilation factor to make name of save model\n",
    "hp_bn = True\n",
    "hp_nf = 80\n",
    "hp_dr = 0.07\n",
    "hp_ks = 6\n",
    "\n",
    "input_size = 6\n",
    "output_size = 2\n",
    "num_fct = 48\n",
    "batch_size = 8\n",
    "n_iter_search = 20\n",
    "num_epoch = 600\n",
    "dev_stn_id = 47105\n",
    "#tran_data_per = \"2101_2104_2201_2204\"\n",
    "#test_data_per = \"2301_2304\"\n",
    "\n",
    "exp_name = \"CNTL\"\n",
    "csv_outdir = './DAOU/LOSS/' + exp_name + '/'\n",
    "model_outdir = './DAOU/MODL/' + exp_name + '/'\n",
    "scalr_outdir = './DAOU/SCAL/' + exp_name + '/'\n",
    "gifd_outdir = './GIFD/' + exp_name + '/'\n",
    "log_outdir = './DAOU/LOGF/' + exp_name + '/'\n",
    "\n",
    "\n",
    "if os.path.exists(csv_outdir) != True: os.makedirs(csv_outdir)\n",
    "if os.path.exists(model_outdir) != True: os.makedirs(model_outdir)\n",
    "if os.path.exists(scalr_outdir) != True: os.makedirs(scalr_outdir)\n",
    "if os.path.exists(gifd_outdir) != True: os.makedirs(gifd_outdir)\n",
    "if os.path.exists(log_outdir) != True: os.makedirs(log_outdir)\n",
    "\n",
    "\n",
    "nwp_file = \"../DAIO/nwp_data_47105\"\n",
    "obs_file = \"../DAIO/obs_data_47105\"\n",
    "\n",
    "sel_dm_nwp_train, sel_dm_nwp_test, dm_obs_train, dm_obs_test = data_load(nwp_file, obs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Final training data shape\n",
      "<class 'numpy.ndarray'>\n",
      "tran nwp :  (108, 48, 6)\n",
      "tran obs :  (108, 48, 2)\n",
      "test nwp :  (56, 48, 6)\n",
      "test obs :  (56, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "# .. 스케일링 및 데이터 분할\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './INC')\n",
    "from step_sampling_for_date import step_sampling_for_date\n",
    "from hist_and_kde_for_split import hist_and_kde_for_split, hist_and_kde_for_split_UV\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Normalize\n",
    "\n",
    "output_size = 2\n",
    "\n",
    "# .. initialaize\n",
    "tr_b, tr_s, tr_f = sel_dm_nwp_train.shape[0], sel_dm_nwp_train.shape[1], sel_dm_nwp_train.shape[2]      \n",
    "ts_b, ts_s, ts_f = sel_dm_nwp_test.shape[0], sel_dm_nwp_test.shape[1], sel_dm_nwp_test.shape[2]      \n",
    "\n",
    "# .. get restorator with obs range\n",
    "nwp_scaler = MinMaxScaler()   # copy default true\n",
    "obs_scaler = MinMaxScaler()\n",
    "nwp_scaler.fit(sel_dm_nwp_train.view().reshape(tr_b*tr_s, tr_f))\n",
    "obs_scaler.fit(dm_obs_train.view().reshape(tr_b*tr_s, output_size))\n",
    "\n",
    "# .. feature normalize   ( train seq, feature = test seq, feature )\n",
    "nor_dm_nwp_train = nwp_scaler.transform(sel_dm_nwp_train.reshape(tr_b*tr_s, tr_f))\n",
    "nor_dm_nwp_train = nor_dm_nwp_train.reshape(tr_b,tr_s,tr_f)\n",
    "nor_dm_nwp_test = nwp_scaler.transform(sel_dm_nwp_test.reshape(ts_b*ts_s, ts_f))\n",
    "nor_dm_nwp_test = nor_dm_nwp_test.reshape(ts_b,ts_s,ts_f)\n",
    "\n",
    "nor_dm_obs_train = obs_scaler.transform(dm_obs_train.reshape(tr_b*tr_s, output_size))\n",
    "nor_dm_obs_train = nor_dm_obs_train.reshape(tr_b,tr_s, output_size)\n",
    "nor_dm_obs_test = obs_scaler.transform(dm_obs_test.reshape(ts_b*ts_s, output_size))\n",
    "nor_dm_obs_test = nor_dm_obs_test.reshape(ts_b,ts_s, output_size)\n",
    "\n",
    "\n",
    "print ('---------- Final training data shape')\n",
    "print(type(nor_dm_nwp_train))\n",
    "print ('tran nwp : ', nor_dm_nwp_train.shape)\n",
    "print ('tran obs : ', nor_dm_obs_train.shape)\n",
    "print ('test nwp : ', nor_dm_nwp_test.shape)\n",
    "print ('test obs : ', nor_dm_obs_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model:  ../MODL/DAOU/MODL/CNTL/tcn_modl_var6_e1000_bs8_lr0.009_nf85_pdsame_ks3_dr0.07_dl4_ns1_2101_2104_2201_2204_47105.h5\n",
      "4/4 [==============================] - 1s 47ms/step\n",
      "(108, 48, 2)\n",
      "2/2 [==============================] - 0s 92ms/step\n",
      "(56, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# .. Model load\n",
    "from tensorflow.keras.models import load_model\n",
    "#model_name = \"../MODL/DAOU/MODL/CNTL/tcn_modl_var6_e1000_bs8_lr0.009_nf87_pdsame_ks6_dr0.07_dl48_ns1_2101_2104_2201_2204_47105.h5\"\n",
    "\n",
    "#hyper band\n",
    "model_name = \"../MODL/DAOU/MODL/CNTL/tcn_modl_var6_e1000_bs8_lr0.009_nf85_pdsame_ks3_dr0.07_dl4_ns1_2101_2104_2201_2204_47105.h5\"\n",
    "\n",
    "#bayesian\n",
    "#model_name = \"../MODL/DAOU/MODL/CNTL/tcn_modl_var6_e1000_bs8_lr0.009_nf95_pdsame_ks3_dr0.07_dl4_ns1_2101_2104_2201_2204_47105.h5\"\n",
    "\n",
    "print (\"load_model: \", model_name)\n",
    "model = load_model(model_name, custom_objects={'TCN':TCN} )\n",
    "\n",
    "# train\n",
    "nor_pred_train_y = model.predict(nor_dm_nwp_train)\n",
    "inv_pred_train = obs_scaler.inverse_transform(nor_pred_train_y.reshape(tr_b*tr_s, output_size))\n",
    "inv_pred_train = inv_pred_train.reshape(tr_b,tr_s, output_size)\n",
    "print(inv_pred_train.shape)\n",
    "# test\n",
    "nor_pred_test_y = model.predict(nor_dm_nwp_test)\n",
    "inv_pred_test = obs_scaler.inverse_transform(nor_pred_test_y.reshape(ts_b*ts_s, output_size))\n",
    "inv_pred_test = inv_pred_test.reshape(ts_b,ts_s, output_size)\n",
    "print(inv_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "있어야할 day수:  31\n",
      "있어야할 day수:  30\n",
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "[15]\n"
     ]
    }
   ],
   "source": [
    "set_dates_1 = pd.date_range('2023-01-01 09:00:00', '2023-01-31 09:00:00', freq='D')\n",
    "set_dates_4 = pd.date_range('2023-04-01 09:00:00', '2023-04-30 09:00:00', freq='D')\n",
    "print(\"있어야할 day수: \", len(set_dates_1))\n",
    "print(\"있어야할 day수: \", len(set_dates_4))\n",
    "\n",
    "print(type(set_dates_1))\n",
    "\n",
    "combined_series = set_dates_1.union(set_dates_4)\n",
    "print(np.where(combined_series=='2023-01-16 09:00:00')[0])\n",
    "\n",
    "#print(combined_series.get_loc(\"2021-01-14 09:00:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc ==================================================\n",
      "        u_bias    v_bias    u_rmse    v_rmse  spd_bias  spd_rmse    cosine\n",
      "ldps -0.037264  0.099751  2.520820  2.448330  1.412082  2.412164  0.524739\n",
      "tcnm  0.189512  0.061466  0.376601  0.294432  0.077020  0.361745  0.740320\n",
      "test acc ==================================================\n",
      "        u_bias    v_bias    u_rmse    v_rmse  spd_bias  spd_rmse    cosine\n",
      "ldps -0.590387  1.412058  2.871175  3.295231  1.236993  2.431277  0.268869\n",
      "tcnm -0.034083  1.334855  1.711763  1.919569 -0.314486  1.425989  0.380336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(0, '../MODL/INC/')\n",
    "from calc_stastics import bias_rmse\n",
    "from uv_to_wind import uv_to_wind\n",
    "\n",
    "\n",
    "\n",
    "def calc_bias(pred, target):\n",
    "    bias = pred - target\n",
    "    mean_bias = np.mean(bias, axis=0)\n",
    "    return mean_bias\n",
    "\n",
    "\n",
    "def calc_rmse(pred, target):\n",
    "    se = (pred - target)**2\n",
    "    rmse = np.sqrt( np.mean(se, axis=0) )\n",
    "    return rmse\n",
    "\n",
    "\n",
    "\n",
    "def calc_error(nwp, pred, obs):\n",
    "\n",
    "    ldps_u_bias = calc_bias(nwp[:,:,1], obs[:,:,0])\n",
    "    ldps_v_bias = calc_bias(nwp[:,:,2], obs[:,:,1])\n",
    "    tcnm_u_bias = calc_bias(pred[:,:,0], obs[:,:,0])\n",
    "    tcnm_v_bias = calc_bias(pred[:,:,1], obs[:,:,1])\n",
    "    ldps_u_rmse = calc_rmse(nwp[:,:,1], obs[:,:,0])\n",
    "    ldps_v_rmse = calc_rmse(nwp[:,:,2], obs[:,:,1])\n",
    "    tcnm_u_rmse = calc_rmse(pred[:,:,0], obs[:,:,0])\n",
    "    tcnm_v_rmse = calc_rmse(pred[:,:,1], obs[:,:,1])\n",
    "\n",
    "    cosine_s = metrics.CosineSimilarity(axis=1)\n",
    "    cosine_s.update_state(nwp[:,:,1:3].reshape(-1,2), obs[:,:,0:2].reshape(-1,2))\n",
    "    ldps_w_coss = cosine_s.result().numpy()\n",
    "    cosine_s.update_state(pred[:,:,:].reshape(-1,2), obs[:,:,0:2].reshape(-1,2))\n",
    "    tcnm_w_coss = cosine_s.result().numpy()\n",
    "\n",
    "    ndim_uv_to_wind = np.vectorize(uv_to_wind)\n",
    "    nwp_spd, nwp_dir = ndim_uv_to_wind(nwp[:,:,1], nwp[:,:,2])\n",
    "    prd_spd, prd_dir = ndim_uv_to_wind(pred[:,:,0], pred[:,:,1])\n",
    "    obs_spd, obs_dir = ndim_uv_to_wind(obs[:,:,0], obs[:,:,1])\n",
    "\n",
    "    #print(nwp_spd.shape)\n",
    "    #print(prd_spd.shape)\n",
    "    #print(obs_spd.shape)\n",
    "\n",
    "    \n",
    "    ldps_spd_bias = calc_bias(nwp_spd[:,:], obs_spd[:,:])\n",
    "    tcnm_spd_bias = calc_bias(prd_spd[:,:], obs_spd[:,:])\n",
    "    ldps_spd_rmse = calc_rmse(nwp_spd[:,:], obs_spd[:,:])\n",
    "    tcnm_spd_rmse = calc_rmse(prd_spd[:,:], obs_spd[:,:])\n",
    "    \n",
    "\n",
    "    error_put = {'u_bias': [np.mean(ldps_u_bias), np.mean(tcnm_u_bias)],\n",
    "                 'v_bias': [np.mean(ldps_v_bias), np.mean(tcnm_v_bias)],\n",
    "                 'u_rmse': [np.mean(ldps_u_rmse), np.mean(tcnm_u_rmse)],\n",
    "                 'v_rmse': [np.mean(ldps_v_rmse), np.mean(tcnm_v_rmse)],\n",
    "                 'spd_bias': [np.mean(ldps_spd_bias), np.mean(tcnm_spd_bias)],\n",
    "                 'spd_rmse': [np.mean(ldps_spd_rmse), np.mean(tcnm_spd_rmse)],\n",
    "                 'cosine': [np.mean(ldps_w_coss), np.mean(tcnm_w_coss)]\n",
    "              }\n",
    "    \n",
    "    error_df = pd.DataFrame(error_put, index=['ldps', 'tcnm'])\n",
    "    print(error_df)\n",
    "\n",
    "print(\"train acc\",\"=\"*50)\n",
    "calc_error(sel_dm_nwp_train, inv_pred_train, dm_obs_train)\n",
    "print(\"test acc\",\"=\"*50)\n",
    "calc_error(sel_dm_nwp_test, inv_pred_test, dm_obs_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot case\n",
    "# sel_time = -20\n",
    "# put_df = {'ldps':ldps_spd[sel_time,:], 'tcnm':tcnm_spd[sel_time,:], 'obs': obsd_spd[sel_time,:] }\n",
    "# df = pd.DataFrame(data = put_df)\n",
    "# df.plot.line()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "#-------------------------------------------------------------------------\n",
    "#  Purpose : Read training binary set \n",
    "#  Author  : KIM MK\n",
    "#  Content : \n",
    "#     1. binary file load\n",
    "#     2. preprocessing\n",
    "#     3. forecast\n",
    "#     5. plot\n",
    "#  History : \n",
    "#       Code by Aug. 13, 2018 ManKi Kim\n",
    "#          - import read fortran subroutine\n",
    "#        Add by Aug. 23, 2018 ManKi Kim\n",
    "#          -           \n",
    "#-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Module load\n",
    "\n",
    "#.. module\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "from tensorflow.keras import backend as K\n",
    "import joblib\n",
    "from tcn import TCN\n",
    "import copy\n",
    "\n",
    "#.. local\n",
    "import sys\n",
    "sys.path.insert(0, './inc')\n",
    "from test_data_load import test_data_load\n",
    "from test_find_stnidx import find_stn_idx\n",
    "from check_missing_existence import check_missing_existence\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Custum function\n",
    "\n",
    "def sort_use_stnid(str):\n",
    "        mlist_stn_id = str.split('_')[-1]\n",
    "        mlist_stn_id = mlist_stn_id.split('.')[0]\n",
    "        return int(mlist_stn_id)\n",
    "\n",
    "\n",
    "\n",
    "def model_list(load_dir, tran_peri, each_stn_mod):\n",
    "        model_list = []\n",
    "        list = np.array(os.listdir(load_dir))\n",
    "        for i in range(len(list)):\n",
    "            if each_stn_mod == \"ON\":\n",
    "               if list[i].find(find_ep)>0 and list[i].find(tran_peri[0])>0 and list[i].find('h5')>0 and list[i].find(find_pd)>0 and list[i].find(find_ks)>0 and list[i].find(find_ns)>0 and list[i].find(find_dl)>0 and list[i].find(find_lr)>0 and list[i].find(find_nf)>0 and list[i].find(find_id)>0 :\n",
    "                  model_list.append(list[i])\n",
    "            else:\n",
    "               if list[i].find(find_ep)>0 and list[i].find(tran_peri[0])>0 and list[i].find('h5')>0 and list[i].find(find_pd)>0 and list[i].find(find_ks)>0 and list[i].find(find_ns)>0 and list[i].find(find_dl)>0 and list[i].find(find_lr)>0 and list[i].find(find_nf)>0 :\n",
    "                  model_list.append(list[i])\n",
    "\n",
    "        model_list.sort(key=sort_use_stnid)\n",
    "\n",
    "        #return np.array(model_list)\n",
    "        return model_list\n",
    "\n",
    "\n",
    "\n",
    "def scaler_list(load_dir, tran_peri, each_stn_mod):\n",
    "        obs_scaler_list = []\n",
    "        nwp_scaler_list = []\n",
    "        list = np.array(os.listdir(load_dir))\n",
    "        for i in range(len(list)):\n",
    "            if each_stn_mod == \"ON\":\n",
    "               if list[i].find(find_ep)>0 and list[i].find(tran_peri[0])>0 and list[i].find(find_pd)>0 and list[i].find(find_ks)>0 and list[i].find(find_ns)>0 and list[i].find(find_dl)>0 and list[i].find(find_lr)>0 and list[i].find(find_nf)>0 and list[i].find(find_id)>0 :\n",
    "                  if list[i].find(\"obs\") >= 0: obs_scaler_list.append(list[i])\n",
    "                  if list[i].find(\"nwp\") >= 0: nwp_scaler_list.append(list[i])\n",
    "            else:\n",
    "               if list[i].find(find_ep)>0 and list[i].find(tran_peri[0])>0 and list[i].find(find_pd)>0 and list[i].find(find_ks)>0 and list[i].find(find_ns)>0 and list[i].find(find_dl)>0 and list[i].find(find_lr)>0 and list[i].find(find_nf)>0 :\n",
    "                  if list[i].find(\"obs\") >= 0: obs_scaler_list.append(list[i])\n",
    "                  if list[i].find(\"nwp\") >= 0: nwp_scaler_list.append(list[i])\n",
    "\n",
    "        obs_scaler_list.sort(key=sort_use_stnid)\n",
    "        nwp_scaler_list.sort(key=sort_use_stnid)\n",
    "\n",
    "        return np.array(nwp_scaler_list), np.array(obs_scaler_list)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Device configuration\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Data set\n",
    "\n",
    "utc = '00'\n",
    "#exp_name = \"SPD_1ST_TEST_NOOPT\"\n",
    "exp_name = \"OP_\" + utc + \"UTC\"\n",
    "home = '/home/mankicom/STD_POOL/SHRT_GDPS/HOURLY1/MODL_DVLP/SPD/TEST'\n",
    "#home = '/h3/home/nwpr/mankicom/STD_POOL/SHRT_GDPS/HOURLY1/MODL_DVLP/SPD/TEST'\n",
    "load_dir = home + '/DAOU'\n",
    "each_stn_mod = \"OFF\"\n",
    "\n",
    "\n",
    "\n",
    "## .. var7 47108 best\n",
    "stn_id = 47108\n",
    "#stn_id = 47169\n",
    "#stn_id = 47119\n",
    "#stn_id = 47165\n",
    "find_id = str(stn_id)\n",
    "find_var = 'var10'\n",
    "#find_pd = 'pdcausal'    # padding\n",
    "find_pd = 'pdsame'    # padding\n",
    "find_ks = 'ks6'      # kernel size\n",
    "find_ns = 'ns1'       # nb_stacks\n",
    "find_nf = 'nf87'       # nb_filters\n",
    "find_dl = 'dl136'       # last dilation\n",
    "find_lr = 'lr0.009'\n",
    "find_ep = 'e1000'\n",
    "\n",
    "\n",
    "data_dir = '../DAIN/'\n",
    "#data_dir = '../DAIN_3HR_EXP8/'           # for 47119, 47165\n",
    "prt_outdir = '../DAIO/' + exp_name + \"/\"\n",
    "if os.path.exists(prt_outdir) != True: os.mkdir(prt_outdir)\n",
    "\n",
    "\n",
    "mdl_dir = \"/MODL/\" + exp_name + \"/\"\n",
    "scl_dir = \"/SCAL/\" + exp_name + \"/\"\n",
    "#mdl_dir = \"/MODL/\"\n",
    "#scl_dir = \"/SCAL/\"\n",
    "#mdl_dir = \"/MODL/TCNM_IMPV_EXP8_\" + utc + \"UTC/\"\n",
    "#scl_dir = \"/SCAL/TCNM_IMPV_EXP8_\" + utc + \"UTC/\"\n",
    "\n",
    "\n",
    "#.. exp\n",
    "tran_name = [ '-24-1605-2104' ]\n",
    "tran_peri = [ '20160501'+utc+'-20210430'+utc ]\n",
    "tran_peri_name = [ tran_peri[0] + tran_name[0] ]\n",
    "\n",
    "\n",
    "test_name = [ '2105', '2106', '2107', '2108', '2109', '2110', '2111', '2112' ]\n",
    "test_peri = [ '20210501'+utc+'-20210531'+utc+'-24-',\n",
    "              '20210601'+utc+'-20210630'+utc+'-24-',\n",
    "              '20210701'+utc+'-20210731'+utc+'-24-',\n",
    "              '20210801'+utc+'-20210831'+utc+'-24-',\n",
    "              '20210901'+utc+'-20210930'+utc+'-24-',\n",
    "              '20211001'+utc+'-20211031'+utc+'-24-',\n",
    "              '20211101'+utc+'-20211130'+utc+'-24-',\n",
    "              '20211201'+utc+'-20211231'+utc+'-24-']\n",
    "test_peri_name = [ test_peri[0] + test_name[0],\n",
    "                   test_peri[1] + test_name[1],\n",
    "                   test_peri[2] + test_name[2],\n",
    "                   test_peri[3] + test_name[3],\n",
    "                   test_peri[4] + test_name[4],\n",
    "                   test_peri[5] + test_name[5],\n",
    "                   test_peri[6] + test_name[6],\n",
    "                   test_peri[7] + test_name[7] ]\n",
    "total_test_peri = '2105'+utc+'-2112'+utc\n",
    "num_his = [ 31, 30, 31, 31, 30, 31, 30, 31 ]\n",
    "\n",
    "\n",
    "element = 'ALLV'\n",
    "\n",
    "num_fct = 136\n",
    "num_ele = 10\n",
    "\n",
    "input_size = num_ele\n",
    "output_size = 1\n",
    "\n",
    "print ('# of validation month' , len(test_name))\n",
    "\n",
    "if each_stn_mod == \"ON\":\n",
    "   obs_stn_list = '../DABA/stn_47108.dat'\n",
    "else:\n",
    "   #obs_stn_list = '../DABA/stn_expand_test_2019081200.dat'\n",
    "   #obs_stn_list = '../DABA/stn_opimprv_test_2019081200.dat'\n",
    "   obs_stn_list = '../DABA/new_dfs_merg_station_directory_2021050100.dat'\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Model & Scaler list load\n",
    "\n",
    "print(load_dir+mdl_dir)\n",
    "model_list = model_list(load_dir+mdl_dir, tran_peri, each_stn_mod)\n",
    "nwp_scaler_list, obs_scaler_list = scaler_list(load_dir+scl_dir, tran_peri, each_stn_mod)\n",
    "\n",
    "print(\"------ Check model, scaler set list\")\n",
    "for i in range(len(model_list)):\n",
    "    print  (model_list[i], nwp_scaler_list[i], obs_scaler_list[i])\n",
    "print(\"model_list type: \", type(model_list))\n",
    "\n",
    "mod_stn_id = []\n",
    "for i in range(len(model_list)):\n",
    "    stn_id = (model_list[i].split('_'))[13]\n",
    "    stn_id = (stn_id.split('.'))[0]\n",
    "    mod_stn_id.append(stn_id)\n",
    "mod_stn_id = list(map(int, mod_stn_id))\n",
    "\n",
    "print(type(mod_stn_id[0]))\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Read stn list\n",
    "\n",
    "# .. all station\n",
    "test_x_all = np.ndarray( shape=( len(num_his), 31, num_fct, len(model_list), input_size ), dtype=np.float32 )\n",
    "test_y_all = np.ndarray( shape=( len(num_his), 31, num_fct, len(model_list), output_size ), dtype=np.float32 )\n",
    "pred_test_all = np.ndarray( shape=( len(num_his), 31, num_fct, len(model_list), output_size ), dtype=np.float32 )\n",
    "\n",
    "\n",
    "pred_test_all.fill(np.nan)\n",
    "test_x_all.fill(np.nan)\n",
    "test_y_all.fill(np.nan)\n",
    "\n",
    "\n",
    "#for i in range(5):    # for models\n",
    "for i in range(len(model_list)):    # for models\n",
    "#for i in range(dev_stn_id.shape[0]):    # for some stations\n",
    "#for i in [100, 200, 300 ]:    # for some stations\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # .. Run LSTM forecast \n",
    "\n",
    "    if len(model_list)!=1:\n",
    "       run_stn_id = mod_stn_id[i]\n",
    "    else:\n",
    "       run_stn_id = mod_stn_id\n",
    "\n",
    "    print ( \"=================== Start {} station\".format(run_stn_id) )\n",
    "\n",
    "    # .. clear model\n",
    "    K.clear_session()\n",
    "\n",
    "    # .. Load model \n",
    "    model_name = load_dir + mdl_dir + model_list[i]\n",
    "    try:\n",
    "       print (\"load_model: \", model_list[i])\n",
    "       model = load_model(model_name, custom_objects={'TCN':TCN} )\n",
    "    except:\n",
    "       print (\"Error: Could not load \", model_name)\n",
    "       continue       \n",
    "   \n",
    "\n",
    "    # .. Load scaler\n",
    "    print (\"load_scaler:\", nwp_scaler_list[i])\n",
    "    print (\"load_scaler:\", obs_scaler_list[i])\n",
    "    nwp_scaler = joblib.load(load_dir + scl_dir + nwp_scaler_list[i])\n",
    "    obs_scaler = joblib.load(load_dir + scl_dir + obs_scaler_list[i])\n",
    "\n",
    "\n",
    "    for k in range(len(test_name)):  # for days\n",
    "    #for k in [4]:  # for days\n",
    "\n",
    "        #-------------------------------------------------------------------------\n",
    "        # .. Data load\n",
    "\n",
    "        print(test_peri_name[k])\n",
    "\n",
    "        test_x, test_y = test_data_load(data_dir, test_peri_name[k], element,\n",
    "                                        input_size, output_size, num_his[k],\n",
    "                                        num_fct, run_stn_id)\n",
    "\n",
    "        test_x = np.swapaxes(test_x,0,1)\n",
    "        #test_x_ori = copy.deepcopy(test_x)\n",
    "        test_y = np.swapaxes(test_y,0,1)\n",
    "\n",
    "\n",
    "        print (\"======= Loaded data shape \")\n",
    "        print (\"test_x shape: \", test_x.shape)\n",
    "        print (\"test_y shape: \", test_y.shape)\n",
    "\n",
    " \n",
    "        # .. load data  \n",
    "        b, s, f = test_x.shape\n",
    "\n",
    "        #---------------------------------------------------------------------\n",
    "        # .. Model run\n",
    "\n",
    "        # .. 2021.02.25 kmk\n",
    "        for j in range(b):\n",
    "\n",
    "            # .. check missing\n",
    "            nwp_count = check_missing_existence(test_x[j,:,:], test_y[j,:,:]) \n",
    "            if nwp_count > 0:\n",
    "               print ( \"------- nwp missing count > 0, pass \", j, '  day' )\n",
    "               continue\n",
    "\n",
    "            # .. normalize\n",
    "            nor_test_x = nwp_scaler.transform(test_x[j:j+1,:,:].reshape(1*s,f))          # scaler input dim=(N,n_feature)\n",
    "            nor_test_y = obs_scaler.transform(test_y[j:j+1,:,:].reshape(1*s,output_size))\n",
    "            nor_test_x = nor_test_x.reshape(1,s,f)\n",
    "            nor_test_y = nor_test_y.reshape(1,s,output_size)\n",
    "\n",
    "            nor_pred_test = model.predict(nor_test_x, batch_size=1)    \n",
    "            inv_pred_test = obs_scaler.inverse_transform(nor_pred_test.reshape(1*s,output_size))\n",
    "            inv_pred_test = inv_pred_test.reshape(s,output_size)\n",
    "\n",
    "            # .. Data save\n",
    "            test_x_all[k,j,:,i,:] = test_x[j,:,:]  # select feature 0\n",
    "            test_y_all[k,j,:,i,:] = test_y[j,:,:]  # select feature 0\n",
    "            pred_test_all[k,j,:,i,:] = inv_pred_test[:,:] # select feature 0\n",
    "\n",
    "\n",
    "#pred_test_all = pred_test_all[:,:,2:-2,:]\n",
    "#test_x_all = test_x_all[:,:,2:-2,:]\n",
    "#test_y_all = test_y_all[:,:,2:-2,:]\n",
    "print (\"-------------- all list fcst complete\")\n",
    "print (\"pred_test_all: \", pred_test_all.shape)\n",
    "print (\"test_x_all: \", test_x_all.shape)\n",
    "print (\"test_y_all: \", test_y_all.shape)\n",
    "\n",
    "#print ( pred_test_all )\n",
    "\n",
    "if each_stn_mod == \"ON\":\n",
    "   np.savez( (prt_outdir + 'tcnm' + '_' + total_test_peri + '_' + find_ep + '_' + find_id), value=pred_test_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'g128' + '_' + total_test_peri + '_' + find_ep + '_' + find_id), value=test_x_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'tobs' + '_' + total_test_peri + '_' + find_ep + '_' + find_id), value=test_y_all, stn_id=mod_stn_id )\n",
    "else:\n",
    "   np.savez( (prt_outdir + 'tcnm' + '_' + total_test_peri + '_' + find_ep ), value=pred_test_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'g128' + '_' + total_test_peri + '_' + find_ep ), value=test_x_all, stn_id=mod_stn_id )\n",
    "   np.savez( (prt_outdir + 'tobs' + '_' + total_test_peri + '_' + find_ep ), value=test_y_all, stn_id=mod_stn_id )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

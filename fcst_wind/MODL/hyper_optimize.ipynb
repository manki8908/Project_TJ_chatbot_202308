{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# if gpus:\n",
    "\n",
    "#     try:\n",
    "\n",
    "#         for gpu in gpus:\n",
    "\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#     except RuntimeError as e:\n",
    "\n",
    "#         print(e)\n",
    "\n",
    "# # 실행가능한 gpu 목록\n",
    "# tf.config.list_physical_devices('GPU')\n",
    "# #실행가능한 cpu, gpu 목록\n",
    "# from tensorflow.python.client import device_lib\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "from tensorflow.keras import Input, Model, callbacks\n",
    "from tensorflow.keras.utils import plot_model as plm\n",
    "from tensorflow.keras.activations import swish\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tcn import TCN, tcn_full_summary\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Set configure\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Data set\n",
    "\n",
    "element = 'ALLV'\n",
    "name_list = \"./SHEL/namelist.input\"\n",
    "\n",
    "hp_lr = 0.009\n",
    "hp_pd = 'same'\n",
    "hp_ns = 1\n",
    "hp_dl = [1,2,4,8,16,32,48]\n",
    "hp_ldl = hp_dl[-1] # last dilation factor to make name of save model\n",
    "hp_bn = True\n",
    "hp_nf = 80\n",
    "hp_dr = 0.07\n",
    "hp_ks = 6\n",
    "\n",
    "input_size = 6\n",
    "output_size = 2\n",
    "num_fct = 48\n",
    "batch_size = 8\n",
    "n_iter_search = 20\n",
    "num_epoch = 600\n",
    "#dev_stn_id = 47105\n",
    "dev_stn_id = 875\n",
    "tran_data_per = \"2101_2104_2201_2204\"\n",
    "\n",
    "exp_name = \"CNTL\"\n",
    "csv_outdir = './DAOU/LOSS/' + exp_name + '/'\n",
    "model_outdir = './DAOU/MODL/' + exp_name + '/'\n",
    "scalr_outdir = './DAOU/SCAL/' + exp_name + '/'\n",
    "gifd_outdir = './GIFD/' + exp_name + '/'\n",
    "log_outdir = './DAOU/LOGF/' + exp_name + '/'\n",
    "\n",
    "\n",
    "if os.path.exists(csv_outdir) != True: os.makedirs(csv_outdir)\n",
    "if os.path.exists(model_outdir) != True: os.makedirs(model_outdir)\n",
    "if os.path.exists(scalr_outdir) != True: os.makedirs(scalr_outdir)\n",
    "if os.path.exists(gifd_outdir) != True: os.makedirs(gifd_outdir)\n",
    "if os.path.exists(log_outdir) != True: os.makedirs(log_outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== load data shape\n",
      "(868, 49, 20)\n",
      "(868, 49, 2)\n",
      "================================================== split data shape\n",
      "(109, 49, 20)\n",
      "(109, 49, 2)\n",
      "(61, 49, 20)\n",
      "(61, 49, 2)\n",
      "결측 합계:  14\n",
      "shape of after drop\n",
      "(95, 49, 20)\n",
      "(95, 49, 2)\n",
      "결측 합계:  4\n",
      "shape of after drop\n",
      "(57, 49, 20)\n",
      "(57, 49, 2)\n",
      "================================================== drop data shape\n",
      "(95, 48, 6)\n",
      "(95, 48, 2)\n",
      "(57, 48, 6)\n",
      "(57, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../config/')\n",
    "from global_params import variable_info\n",
    "#from config.global_params import variable_info\n",
    "\n",
    "sys.path.insert(0, './INC/')\n",
    "from data_split import data_split\n",
    "\n",
    "\n",
    "\n",
    "# 인풋 준비\n",
    "nwp_file = f\"../DAIO/nwp_data_{dev_stn_id}\"\n",
    "obs_file = f\"../DAIO/obs_data_{dev_stn_id}\"\n",
    "nwp_data = np.load(nwp_file)\n",
    "obs_data = np.load(obs_file)\n",
    "print(\"=\"*50, \"load data shape\")\n",
    "print(nwp_data.shape)\n",
    "print(obs_data.shape)\n",
    "\n",
    "\n",
    "# train([21.01,04, 22.01,04]) / test([23.01,04]) 분할  \n",
    "class_split = data_split(nwp_data, obs_data)\n",
    "train_nwp, test_nwp, train_obs, test_obs = class_split.get_split_data()\n",
    "print(\"=\"*50, \"split data shape\")\n",
    "print(train_nwp.shape)\n",
    "print(train_obs.shape)\n",
    "print(test_nwp.shape)\n",
    "print(test_obs.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 결측제거\n",
    "missing_nwp_train = set(np.where(np.isnan(train_nwp))[0])\n",
    "missing_obs_train = set(np.where(np.isnan(train_obs))[0])\n",
    "missing_all_train = list(missing_nwp_train | missing_obs_train)\n",
    "print(\"결측 합계: \", len(missing_all_train))\n",
    "dm_nwp_train = np.delete(train_nwp, missing_all_train, 0)\n",
    "dm_obs_train = np.delete(train_obs, missing_all_train, 0)\n",
    "print(\"shape of after drop\")\n",
    "print(dm_nwp_train.shape)\n",
    "print(dm_obs_train.shape)\n",
    "\n",
    "missing_nwp_test = set(np.where(np.isnan(test_nwp))[0])\n",
    "missing_obs_test = set(np.where(np.isnan(test_obs))[0])\n",
    "missing_all_test = list(missing_nwp_test | missing_obs_test)\n",
    "print(\"결측 합계: \", len(missing_all_test))\n",
    "dm_nwp_test = np.delete(test_nwp, missing_all_test, 0)\n",
    "dm_obs_test = np.delete(test_obs, missing_all_test, 0)\n",
    "print(\"shape of after drop\")\n",
    "print(dm_nwp_test.shape)\n",
    "print(dm_obs_test.shape)\n",
    "\n",
    "\n",
    "# 변수선택\n",
    "# for 47105\n",
    "#sel_var = ['NDNSW_surface', 'UGRD_10m', 'VGRD_10m', 'RH_1_5ma', 'MAXGUST_0m', 'PRMSL_meansealevel']\n",
    "# for 875\n",
    "sel_var = ['UGRD_10m', 'VGRD_10m', \"TMP_1_5m\", 'RH_1_5ma', 'PRMSL_meansealevel', \"PRES_surface\"]\n",
    "\n",
    "var_list_dict = list(variable_info.keys())\n",
    "var_index = [ var_list_dict.index(i) for i in sel_var ]\n",
    "#print(var_list_dict)\n",
    "#print(var_index)\n",
    "sel_dm_nwp_train = dm_nwp_train[:,1::,var_index]\n",
    "sel_dm_nwp_test = dm_nwp_test[:,1::,var_index]\n",
    "dm_obs_train = dm_obs_train[:,1::,:]\n",
    "dm_obs_test = dm_obs_test[:,1::,:]\n",
    "\n",
    "\n",
    "print(\"=\"*50, \"drop data shape\")\n",
    "print(sel_dm_nwp_train.shape)\n",
    "print(dm_obs_train.shape)\n",
    "print(sel_dm_nwp_test.shape)\n",
    "print(dm_obs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Final training data shape\n",
      "<class 'numpy.ndarray'>\n",
      "tran nwp :  (95, 48, 6)\n",
      "tran obs :  (95, 48, 2)\n",
      "test nwp :  (57, 48, 6)\n",
      "test obs :  (57, 48, 2)\n",
      "in split, re_nwp_stn shape:  (95, 48, 6)\n",
      "tran nwp shape:  (76, 48, 6) tran obs shape:  (76, 48, 2)\n",
      "vald nwp shape:  (19, 48, 6) vald obs shape:  (19, 48, 2)\n",
      "plotting KDE .. \n",
      "tran_y shape:  (76, 48, 2)\n",
      "vald_y shape:  (19, 48, 2)\n",
      "test_y shape:  (57, 48, 2)\n",
      "tran_obs shape: (76, 48, 1)\n",
      "vald_obs shape: (19, 48, 1)\n",
      "test_obs shape: (57, 48, 1)\n",
      "calc from numpy\n",
      "tran_x_median: 0.54125\n",
      "vald_x_median: 0.546\n",
      "test_x_median: 0.5637500000000001\n",
      "./GIFD/CNTL/KDE_ecmw_tran_vald_obs_uuu2101_2104_2201_2204_875\n",
      "tran_obs shape: (76, 48, 1)\n",
      "vald_obs shape: (19, 48, 1)\n",
      "test_obs shape: (57, 48, 1)\n",
      "calc from numpy\n",
      "tran_x_median: 0.4459122632103688\n",
      "vald_x_median: 0.44503988035892317\n",
      "test_x_median: 0.5388833499501494\n",
      "./GIFD/CNTL/KDE_ecmw_tran_vald_obs_vvv2101_2104_2201_2204_875\n"
     ]
    }
   ],
   "source": [
    "# .. 스케일링 및 데이터 분할\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './INC')\n",
    "from step_sampling_for_date import step_sampling_for_date\n",
    "from hist_and_kde_for_split import hist_and_kde_for_split, hist_and_kde_for_split_UV\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Normalize\n",
    "\n",
    "output_size = 2\n",
    "\n",
    "# .. initialaize\n",
    "tr_b, tr_s, tr_f = sel_dm_nwp_train.shape[0], sel_dm_nwp_train.shape[1], sel_dm_nwp_train.shape[2]      \n",
    "ts_b, ts_s, ts_f = sel_dm_nwp_test.shape[0], sel_dm_nwp_test.shape[1], sel_dm_nwp_test.shape[2]      \n",
    "\n",
    "# .. get restorator with obs range\n",
    "nwp_scaler = MinMaxScaler()   # copy default true\n",
    "obs_scaler = MinMaxScaler()\n",
    "nwp_scaler.fit(sel_dm_nwp_train.view().reshape(tr_b*tr_s, tr_f))\n",
    "obs_scaler.fit(dm_obs_train.view().reshape(tr_b*tr_s, output_size))\n",
    "\n",
    "# .. feature normalize   ( train seq, feature = test seq, feature )\n",
    "nor_dm_nwp_train = nwp_scaler.transform(sel_dm_nwp_train.reshape(tr_b*tr_s, tr_f))\n",
    "nor_dm_nwp_train = nor_dm_nwp_train.reshape(tr_b,tr_s,tr_f)\n",
    "nor_dm_nwp_test = nwp_scaler.transform(sel_dm_nwp_test.reshape(ts_b*ts_s, ts_f))\n",
    "nor_dm_nwp_test = nor_dm_nwp_test.reshape(ts_b,ts_s,ts_f)\n",
    "\n",
    "nor_dm_obs_train = obs_scaler.transform(dm_obs_train.reshape(tr_b*tr_s, output_size))\n",
    "nor_dm_obs_train = nor_dm_obs_train.reshape(tr_b,tr_s, output_size)\n",
    "nor_dm_obs_test = obs_scaler.transform(dm_obs_test.reshape(ts_b*ts_s, output_size))\n",
    "nor_dm_obs_test = nor_dm_obs_test.reshape(ts_b,ts_s, output_size)\n",
    "\n",
    "\n",
    "print ('---------- Final training data shape')\n",
    "print(type(nor_dm_nwp_train))\n",
    "print ('tran nwp : ', nor_dm_nwp_train.shape)\n",
    "print ('tran obs : ', nor_dm_obs_train.shape)\n",
    "print ('test nwp : ', nor_dm_nwp_test.shape)\n",
    "print ('test obs : ', nor_dm_obs_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. split train --> train/valid for hyper-parameter tuning\n",
    "#tran_x, tran_y, vald_x, vald_y = data_split_5years(re_nwp_stn, re_obs_stn, tran_rate, random_seed) \n",
    "tran_rate = 0.8\n",
    "nbin = 10\n",
    "random_seed = 1\n",
    "tran_x, tran_y, vald_x, vald_y = step_sampling_for_date(nor_dm_nwp_train, nor_dm_obs_train, tran_rate, nbin, random_seed)\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Plot tran valid\n",
    "\n",
    "#var_name = ['NDNSW_surface', 'UGRD_10m', 'VGRD_10m', 'RH_1_5ma', 'MAXGUST_0m', 'PRMSL_meansealevel', \"OBS\"]\n",
    "exp_name = \"stn875_hyper\"\n",
    "\n",
    "hist_and_kde_for_split_UV(exp_name, tran_data_per, dev_stn_id, gifd_outdir, tran_y, vald_y, nor_dm_obs_test)\n",
    "#hist_and_kde_for_split(var_name, exp_name, tran_data_per, dev_stn_id, gifd_outdir,\n",
    "#                       tran_x, tran_y, vald_x, vald_y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:  6\n",
      "batch_size:  8\n",
      "time_lenght:  48\n"
     ]
    }
   ],
   "source": [
    "#=========================================================================\n",
    "# .. Model configuration\n",
    "import tensorflow_addons as tfa\n",
    "                \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Set batch for cross-validation\n",
    "\n",
    "print ('input_size: ', input_size)\n",
    "print ('batch_size: ', batch_size)\n",
    "print ('time_lenght: ', num_fct)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Set Model\n",
    "\n",
    "\n",
    "# .. Define model\n",
    "#def create_model(dropout_rate=0.15, nb_filters=7, kernel_size=3): \n",
    "def model_builder(hp): \n",
    "\n",
    "        # set called hyper_params set\n",
    "        hp_nbfilters = hp.Int('nb_filters', min_value = 50, max_value = 100, step = 5)\n",
    "        hp_kernel_size = hp.Int('kernel_size', min_value = 3, max_value = 12, step = 3)\n",
    "        hp_dilation = hp.Int('dilation', min_value = 0, max_value = 4, step = 1)\n",
    "        #hp_dilation = hp.Choice('dilation', values = [[1,2,4], [1,2,4,8], [1,2,4,8,16], [1,2,4,8,16,32], [1,2,4,8,16,32,48]])\n",
    "\n",
    "        dilation_list = [[1,2,4], [1,2,4,8], [1,2,4,8,16], [1,2,4,8,16,32], [1,2,4,8,16,32,48]]\n",
    "        dilation = dilation_list[hp_dilation][:]\n",
    "\n",
    "        \n",
    "\n",
    "        print ('================== Model called ========================')\n",
    "        print ('input_size: ', input_size)\n",
    "        print ('batch_size: ', batch_size)\n",
    "        print ('time_lenght: ', num_fct)\n",
    "        print ('nb_filters: ', hp_nbfilters)\n",
    "        print ('kernel_size: ', hp_kernel_size)\n",
    "        print ('dilations: ', dilation)\n",
    "        dropout_rate = np.round(hp_dr,2)\n",
    "        print ('dropout_rate: ', dropout_rate)\n",
    "        \n",
    "        ## .. clear keras model\n",
    "        K.clear_session()\n",
    "        # .. create model\n",
    "        #i = Input( batch_shape=(batch_size, num_fct, input_size) )\n",
    "        i = Input( batch_shape=(None, num_fct, input_size) )\n",
    "        o = TCN(return_sequences=True,\n",
    "                activation=swish,\n",
    "                nb_filters=hp_nbfilters,\n",
    "                padding=hp_pd,\n",
    "                use_batch_norm = hp_bn,\n",
    "                nb_stacks=hp_ns,\n",
    "                dropout_rate=hp_dr,\n",
    "                kernel_size=hp_kernel_size,\n",
    "                use_skip_connections=True,\n",
    "                dilations=dilation\n",
    "                )(i)\n",
    "        o = TimeDistributed(Dense(output_size, activation='linear'))(o)\n",
    "        # .. compile\n",
    "        adam = optimizers.Adam(learning_rate=hp_lr)\n",
    "        m= Model(inputs=[i], outputs=[o])\n",
    "        m.compile(optimizer=adam, loss='mse', metrics=[tfa.metrics.RSquare(name='r_square')])\n",
    "        #m.compile(optimizer=adam, loss='mse', metrics=[r2_3dim_uv])\n",
    "        m.summary()\n",
    "        return m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Model called ========================\n",
      "input_size:  6\n",
      "batch_size:  8\n",
      "time_lenght:  48\n",
      "nb_filters:  50\n",
      "kernel_size:  3\n",
      "dilations:  [1, 2, 4]\n",
      "dropout_rate:  0.07\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 6)]           0         \n",
      "                                                                 \n",
      " tcn (TCN)                   (None, 48, 50)            40250     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 48, 2)            102       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,352\n",
      "Trainable params: 39,752\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Search space summary\n",
      "Default search space size: 3\n",
      "nb_filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 100, 'step': 5, 'sampling': 'linear'}\n",
      "kernel_size (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 12, 'step': 3, 'sampling': 'linear'}\n",
      "dilation (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 4, 'step': 1, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# pip install keras_tuner\n",
    "# pip install keras_tuner_cv\n",
    "#from keras_tuner_cv.outer_cv import OuterCV\n",
    "#from keras_tuner.tuners import RandomSearch\n",
    "#from sklearn.model_selection import KFold\n",
    "import IPython\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "#from keras_tuner_cv.outer_cv import OuterCV\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Set metrics\n",
    "#tf.keras.metrics.R\n",
    "#f1 = tfa.metrics.F1Score(num_classes = len(CLASSES), average='macro')\n",
    "\n",
    "budget = 100\n",
    "exp_name = '875_B100'\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# .. Use bayes_opt\n",
    "\n",
    "tuner = kt.Hyperband(hypermodel = model_builder,\n",
    "                    objective = kt.Objective('val_r_square', direction='max'), \n",
    "                    max_epochs = budget,\n",
    "                    factor = 3,\n",
    "                    #overwrite=True,\n",
    "                    directory = './OPTM/',\n",
    "                    project_name = exp_name)\n",
    "\n",
    "# tuner = kt.BayesianOptimization(model_builder,\n",
    "#                      objective = kt.Objective('val_r_square', direction='max'),\n",
    "#                      overwrite=True,\n",
    "#                      max_trials=10)\n",
    "\n",
    "\n",
    "# 작성한 Hypermodel 출력\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 21s]\n",
      "val_r_square: -0.05608771741390228\n",
      "\n",
      "Best val_r_square So Far: 0.22174759209156036\n",
      "Total elapsed time: 00h 29m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Hyperband search took 1798.84 seconds parameter settings. \n"
     ]
    }
   ],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)\n",
    "\n",
    "\n",
    "start = time()\n",
    "tuner.search(tran_x, tran_y, epochs = budget, validation_data = (vald_x, vald_y), callbacks = [ClearTrainingOutput()])\n",
    "#tuner.search(tran_x, tran_y, epochs = 600, validation_data = (vald_x, vald_y))\n",
    "\n",
    "print(\"Hyperband search took %.2f seconds\"     \" parameter settings. \" % ((time() - start)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "    best_kernel_size= 3 \n",
      "    best_nb_filters= 55\n",
      "    best_dilations= 0\n",
      "\n",
      "Results summary\n",
      "Results in ./OPTM/875_B100\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_r_square\", direction=\"max\")\n",
      "\n",
      "Trial 0209 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 55\n",
      "kernel_size: 3\n",
      "dilation: 0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0203\n",
      "Score: 0.22174759209156036\n",
      "\n",
      "Trial 0235 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 55\n",
      "kernel_size: 9\n",
      "dilation: 0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0228\n",
      "Score: 0.1836501806974411\n",
      "\n",
      "Trial 0252 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 85\n",
      "kernel_size: 3\n",
      "dilation: 0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.14594219624996185\n",
      "\n",
      "Trial 0147 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 55\n",
      "kernel_size: 6\n",
      "dilation: 0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0145\n",
      "Score: 0.13689209520816803\n",
      "\n",
      "Trial 0246 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 60\n",
      "kernel_size: 3\n",
      "dilation: 1\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0242\n",
      "Score: 0.07763207703828812\n",
      "\n",
      "Trial 0249 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 70\n",
      "kernel_size: 6\n",
      "dilation: 0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.07186660170555115\n",
      "\n",
      "Trial 0146 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 65\n",
      "kernel_size: 3\n",
      "dilation: 0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0142\n",
      "Score: 0.05701133608818054\n",
      "\n",
      "Trial 0208 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 50\n",
      "kernel_size: 6\n",
      "dilation: 0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0207\n",
      "Score: 0.03658198192715645\n",
      "\n",
      "Trial 0253 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 70\n",
      "kernel_size: 12\n",
      "dilation: 1\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: -0.05608771741390228\n",
      "\n",
      "Trial 0245 summary\n",
      "Hyperparameters:\n",
      "nb_filters: 65\n",
      "kernel_size: 9\n",
      "dilation: 3\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0244\n",
      "Score: -0.07447164505720139\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "best_hps\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "    best_kernel_size= {best_hps.get('kernel_size')} \n",
    "    best_nb_filters= {best_hps.get('nb_filters')}\n",
    "    best_dilations= {best_hps.get('dilation')}\n",
    "\"\"\")\n",
    "\n",
    "# 혹은 결과 출력\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseTuner.reload of <keras_tuner.tuners.hyperband.Hyperband object at 0x00000285EB9C44F0>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

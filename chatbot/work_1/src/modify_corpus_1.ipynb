{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 말뭉치 INTENT 훈련 및 사용자 사전 생성 작업\n",
    "* 자료 로드\n",
    "  1. 처음배우는 딥러닝 챗봇 data\n",
    "  2. 등산로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folium Version: 0.14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import folium\n",
    "print(f\"folium Version: {folium.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자료 로드\n",
    "1. 등산로 자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df #:  57890\n",
      "mountain #:  2210\n",
      "loads #:  4879\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#geo_path = '../DABA/seoul-dong.geojson'\n",
    "geo_path = '../../DATA/FRT000801/moutain_load.geojson'\n",
    "try: \n",
    "    df_geo = json.load(open(geo_path, encoding='utf-8'))\n",
    "except:\n",
    "    df_geo = json.load(open(geo_path, econding='utf-8-sig'))   # return dict\n",
    "\n",
    "df_geo.keys()\n",
    "df_geo\n",
    "#df_geo['features']\n",
    "\n",
    "import re\n",
    "from re import search, findall, match, sub\n",
    "\n",
    "# 등산로 명 뽑기\n",
    "#print(df_geo.keys())\n",
    "#print(type(df_geo))\n",
    "print(\"df #: \", len(df_geo['features'][:]))\n",
    "var_mountains = [ df_geo['features'][i]['properties']['MNTN_NM'] for i in range(len(df_geo['features'][:])) ]\n",
    "var_loads = [ df_geo['features'][i]['properties']['PMNTN_NM'] for i in range(len(df_geo['features'][:])) ]\n",
    "\n",
    "#print(mountains[0:5])\n",
    "\n",
    "set_mountains = list(filter(None, set(var_mountains)))\n",
    "set_loads = list(filter(None, set(var_loads)))\n",
    "set_loads = [ i.replace(\",\", \"-\") for i in set_loads ]\n",
    "print(\"mountain #: \", len(set_mountains))\n",
    "print(\"loads #: \", len(set_loads))\n",
    "\n",
    "\n",
    "# 산, 등산로 너무 많음, 랜덤추출로 100개로 줄이기\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "extract_num = 100\n",
    "rand_mtn = random.sample(range(1,len(set_mountains)),extract_num)\n",
    "rand_load = random.sample(range(1,len(set_loads)),extract_num)\n",
    "#rand_mtn = random.sample(range(0,len(set_mountains)),len(set_mountains))\n",
    "#rand_load = random.sample(range(0,len(set_loads)),len(set_loads))\n",
    "\n",
    "print(len(rand_mtn))\n",
    "print(len(rand_load))\n",
    "\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mtn_corpus.txt 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../../DATA/corpus.txt\", 'r', encoding='utf8') as f:\n",
    "#     ori_lines = f.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mtn_train_data.csv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### mtn_train_data.csv 만들기\n",
    "\n",
    "# 1. 0,1,4 라벨만 추출\n",
    "ex_14 = []\n",
    "with open(\"../../DATA/total_train_data1.csv\", 'r', encoding='utf8') as f:\n",
    "    ori_lines = f.readlines()\n",
    "    #print(ori_lines[0:5])\n",
    "    for i, line in enumerate(ori_lines):\n",
    "        query = line.split(\",\")[0]\n",
    "        label = line.split(\",\")[1]\n",
    "        #print(label.strip())\n",
    "        if (label.strip() != \"2\") and (label.strip() != \"3\"):\n",
    "            ex_14.append(line)\n",
    "            #print(line)\n",
    "        #if i == 10: break\n",
    "\n",
    "#print(ex_14[0:5])\n",
    "\n",
    "\n",
    "# 2. 추출값 먼저 write\n",
    "with open(\"../../DATA/mtn_train_data.csv\", 'w', encoding='utf8') as f:\n",
    "   f.writelines(ex_14)\n",
    "\n",
    "# 2.1 조회:2, 등산로 명 데이터 추가            \n",
    "with open(\"../../DATA/mtn_train_data.csv\", 'a', encoding='utf8') as f:\n",
    "\n",
    "   # 일단 산개수만큼\n",
    "   for i in range(len(set_mountains)):\n",
    "           a = re.search('[-._()~,0-9a-zA-Z]', set_mountains[i])\n",
    "           b = re.search('[-._()~,0-9a-zA-Z]', set_loads[i])\n",
    "           # 특수문자 포함 단어 제외\n",
    "           if (a == None) and (b == None) and (len(set_mountains[i].split()) == 1) and (len(set_loads[i].split()) == 1 ):\n",
    "               f.write(f'{set_mountains[i]} {set_loads[i]}, 2')\n",
    "               f.write('\\n')\n",
    "   # 나머지 로드개수만큼\n",
    "   for i in range(len(set_loads) - len(set_mountains)-1,len(set_loads),1):\n",
    "           a = re.search('[-._()~,0-9a-zA-Z]', '관악산')\n",
    "           b = re.search('[-._()~,0-9a-zA-Z]', set_loads[i])\n",
    "           # 특수문자 포함 단어 제외\n",
    "           if (b == None) and (len(set_loads[i].split()) == 1 ):\n",
    "               f.write(f'관악산 {set_loads[i]}, 2')\n",
    "               f.write('\\n')\n",
    "\n",
    "\n",
    "# 2.2 조회:2 시간\n",
    "with open(\"../../DATA/mtn_train_data.csv\", 'a', encoding='utf8') as f:\n",
    "    for i in range(24):\n",
    "        for j in range(60):\n",
    "         f.write(f'{i}시 {j}분, 2')\n",
    "         if i !=49: f.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "# 2.3 선택:3, 등산로 리스트중 선택 기능을 위한 자료 추가\n",
    "with open(\"../../DATA/mtn_train_data.csv\", 'a', encoding='utf8') as f:\n",
    "    for i in range(50):\n",
    "         f.write(f'{i}번, 3')\n",
    "         f.write('\\n')\n",
    "with open(\"../../DATA/mtn_train_data.csv\", 'a', encoding='utf8') as f:\n",
    "    for i in range(50):\n",
    "         f.write(f'{i}, 3')\n",
    "         if i !=49: f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mtn_user_dict.tsv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### mtn_user_dict.tsv 만들기\n",
    "\n",
    "# 1. 기존 정보 불러오기\n",
    "with open(\"../../DATA/user_dic1.tsv\", 'r', encoding='utf8') as f:\n",
    "    ori_lines = f.readlines()\n",
    "\n",
    "with open(\"../../DATA/mtn_user_dict.tsv\", 'w', encoding='utf8') as f:\n",
    "    f.writelines(ori_lines)\n",
    "    f.write('\\n')\n",
    "    # 산 출력\n",
    "    for word in set_mountains:\n",
    "        b = re.search('[-._()~,0-9a-zA-Z]', word)\n",
    "        if b == None:\n",
    "            if len(word.split()) > 1:\n",
    "                for wd in word.split():\n",
    "                    # 여러개면 분리\n",
    "                    print_word = wd + \"\\t\" + \"NNP\"\n",
    "                    f.write(print_word)\n",
    "                    f.write('\\n')\n",
    "            else:\n",
    "                print_word = word + \"\\t\" + \"NNP\"\n",
    "                f.write(print_word)\n",
    "                f.write('\\n')\n",
    "\n",
    "    # 길 이름 출력\n",
    "    for i, sent in enumerate(set_loads):\n",
    "        a = re.search('[-._()~,0-9a-zA-Z]', sent)\n",
    "        # 특수문자 포함 단어 제외\n",
    "        if a == None:\n",
    "            # 여러개면 분리\n",
    "            if len(sent.split()) > 1:\n",
    "                for ww in sent.split():\n",
    "                    print_word = str(ww) + \"\\t\" + \"NNP\"\n",
    "                    f.write(print_word)\n",
    "                    f.write('\\n')\n",
    "                    #if i != len(set_loads)-1: f.write('\\n')\n",
    "            else:\n",
    "                print_word = str(sent) + \"\\t\" + \"NNP\"\n",
    "                f.write(print_word)\n",
    "                f.write('\\n')\n",
    "    # 길이름 분리O\n",
    "    # for i, sent in enumerate(set_loads):\n",
    "    #     a = re.sub('[-.()~,]', ' ', sent)\n",
    "    #     for j in a.split():\n",
    "    #         print_word = str(j) + \"\\t\" + \"NNP\"\n",
    "    #         f.write(print_word)\n",
    "    #         if i != len(set_loads)-1: f.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mtn_ner_train.txt 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ; 수인산 성신리구간 찾아줘\n",
    "# $<수인산:LC> <성산리구간:LC> 찾아줘\n",
    "# 1 수인산  NNP B_LC\n",
    "# 2 성신리구간  NNP B_LC\n",
    "#12\t찾\tVV\tO\n",
    "#12\t아\tEC\tO\n",
    "#12\t주\tVX\tO\n",
    "#12\t어\tEC\tO\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#def print_ner_lines(f, mtn, load, k, n):\n",
    "def print_ner_lines( f, mtn, load):\n",
    "\n",
    "    #print(load)\n",
    "    load_split = re.split('[,/ -]', load)\n",
    "\n",
    "    a = re.search('[-._()~,0-9a-zA-Z]', mtn)\n",
    "    b = re.search('[-._()~,0-9a-zA-Z]', load)\n",
    "\n",
    "    # 특수문자 포함 단어 제외\n",
    "    if (a == None) and (b == None) and (len(load.split()) == 1):\n",
    "\n",
    "        f.write(f'; {mtn} {load}\\n')\n",
    "        f.write(f'$ <{mtn}:LC> <{load}:LC>\\n')\n",
    "        f.write(f'1\\t{mtn}\\tNNP\\tB_LC\\n')\n",
    "        f.write(f'2\\t{load_split[0]}\\tNNP\\tB_LC\\n')\n",
    "        f.write('\\n')\n",
    "        # f.write(f'3\\t찾\\tVV\\tO\\n')\n",
    "        # f.write(f'4\\t아\\tEC\\tO\\n')\n",
    "        # f.write(f'5\\t주\\tVX\\tO\\n')\n",
    "        # f.write(f'6\\t어\\tEC\\tO\\n')\n",
    "    else:\n",
    "        pass\n",
    "        #f.write('\\n')\n",
    "\n",
    "#print_ner_lines(\"수인산\", \"성신리구간\")\n",
    "\n",
    "# 학습 파일 불러오기\n",
    "with open('../../DATA/ner_train1.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "\n",
    "with open('../../DATA/mtn_ner_train_fullversion.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(lines)\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    # # small 100mtn, 100loads\n",
    "    # for k, i in enumerate(rand_mtn):\n",
    "    #     for j in rand_load:            \n",
    "    #         print_ner_lines(f,set_mountains[i],set_loads[j])\n",
    "    #     #if k == 3: break\n",
    "    \n",
    "    # full mtn, loads 2000 * 4000\n",
    "    for i in set_mountains:\n",
    "        run_loads = np.random.choice(set_loads, 2, replace=False)\n",
    "        for j in run_loads:            \n",
    "            print_ner_lines(f,i,j)\n",
    "        \n",
    "    \n",
    "# for i in rand_mtn:\n",
    "#     for j in rand_load:\n",
    "#         print_ner_lines(set_mountains[i],set_loads[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C' 'E' 'B']\n",
      "['E' 'A' 'C']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample1 = np.random.choice(['A', 'B', 'C', 'D', 'E'], 3, replace=False)\n",
    "sample2 = np.random.choice(['A', 'B', 'C', 'D', 'E'], 3, replace=False)\n",
    "\n",
    "print(sample1)\n",
    "print(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"a-b,c d\"\n",
    "a = re.split('[,/ -]', text)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "a=['abc']\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"창동\"\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\"창동 초안산-창동 정화도서관구간\",\n",
    "        \"뉴.정일그린타운뒤구간\",\n",
    "        \"대승사입구구간\",\n",
    "        \"득량면삼정리(오도치재)-미력면초당\",\n",
    "        \"철도공원앞~김천일장군묘구간\",\n",
    "        \"철도공원앞,김천일장군묘구간\"]\n",
    "\n",
    "for i in list1:\n",
    "    a = re.sub('[-.()~,]', ' ', i)\n",
    "    b = a.split()\n",
    "    print(\"=\"*30)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    for j in b:\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "==============================\n",
      "None\n",
      "==============================\n",
      "==============================\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for i in list1:\n",
    "    a = re.search('[-.()~,]', i)\n",
    "    print(\"=\"*30)\n",
    "    if a == None:\n",
    "       print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "len1 = 10\n",
    "len2 = 21\n",
    "\n",
    "for i in range(len1):\n",
    "    print(i)\n",
    "\n",
    "for i in range(len2-len1-1,len2,1):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
